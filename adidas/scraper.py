"""
adidas.jp çˆ¬èŸ² (Playwright + Shopify)
======================================
- ä½¿ç”¨ Playwright æ¨¡æ“¬ç€è¦½å™¨çˆ¬å– adidas.jp
- æ”¯æ´ç”·é‹ / å¥³é‹åˆ†é¡
- å®šåƒ¹å…¬å¼: (adidaså”®åƒ¹ + 1250) / 0.7 = Shopifyå”®åƒ¹ (æ—¥å¹£)
- è‡ªå‹•ä¸Šæ¶åˆ° Shopify
- ç¿»è­¯: æ—¥æ–‡ â†’ ç¹é«”ä¸­æ–‡ (ChatGPT API)
"""

import os
import re
import json
import math
import time
import logging
import requests
from datetime import datetime
from urllib.parse import urljoin, unquote

# ============================================================
# Logging
# ============================================================
logging.basicConfig(
    level=logging.INFO,
    format="[%(levelname)s] %(message)s",
)
logger = logging.getLogger("adidas")

# ============================================================
# ç’°å¢ƒè®Šæ•¸
# ============================================================
SHOPIFY_STORE = os.getenv("SHOPIFY_STORE", "")          # e.g. goyoutati
SHOPIFY_ACCESS_TOKEN = os.getenv("SHOPIFY_ACCESS_TOKEN", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
PROXY_URL = os.getenv("PROXY_URL", "")                  # å¯é¸: http://user:pass@host:port

# ============================================================
# adidas.jp åˆ†é¡ URL
# ============================================================
CATEGORIES = {
    "men_originals": {
        "name": "ç”·é‹ Originals",
        "url": "https://www.adidas.jp/%E3%83%A1%E3%83%B3%E3%82%BA-%E3%82%B7%E3%83%A5%E3%83%BC%E3%82%BA%E3%83%BB%E9%9D%B4-%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%82%B9",
        "collection": "adidas ç”·é‹ Originals",
    },
    "women_originals": {
        "name": "å¥³é‹ Originals",
        "url": "https://www.adidas.jp/%E3%83%AC%E3%83%87%E3%82%A3%E3%83%BC%E3%82%B9-%E3%82%B7%E3%83%A5%E3%83%BC%E3%82%BA%E3%83%BB%E9%9D%B4-%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%82%B9",
        "collection": "adidas å¥³é‹ Originals",
    },
}

# åˆ†é è¨­å®š: æ¯é  48 å€‹å•†å“
ITEMS_PER_PAGE = 48

BASE_URL = "https://www.adidas.jp"


# ============================================================
# å®šåƒ¹å…¬å¼
# ============================================================
def calculate_price(adidas_price_jpy: int) -> int:
    """
    (adidaså”®åƒ¹ + 1250) / 0.7 = Shopifyå”®åƒ¹
    ç„¡æ¢ä»¶é€²ä½åˆ°æ•´æ•¸
    """
    raw = (adidas_price_jpy + 1250) / 0.7
    return math.ceil(raw)


# ============================================================
# ç¿»è­¯ (ChatGPT API)
# ============================================================
def translate_ja_to_zhtw(text: str) -> str:
    """ç”¨ OpenAI ChatGPT å°‡æ—¥æ–‡ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡"""
    if not text or not text.strip():
        return text
    if not OPENAI_API_KEY:
        logger.warning("æœªè¨­å®š OPENAI_API_KEYï¼Œè·³éç¿»è­¯")
        return text

    try:
        resp = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "Content-Type": "application/json",
            },
            json={
                "model": "gpt-4o-mini",
                "messages": [
                    {
                        "role": "system",
                        "content": (
                            "ä½ æ˜¯ç¿»è­¯å°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹æ—¥æ–‡ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚"
                            "åªå›å‚³ç¿»è­¯çµæœï¼Œä¸è¦åŠ ä»»ä½•è§£é‡‹ã€‚"
                            "å“ç‰Œåå’Œå‹è™Ÿåä¿ç•™åŸæ–‡ï¼ˆè‹±æ–‡ï¼‰ã€‚"
                            "å¦‚æœåŸæ–‡å·²ç¶“æ˜¯è‹±æ–‡æˆ–ä¸­æ–‡ï¼Œç›´æ¥å›å‚³åŸæ–‡ã€‚"
                        ),
                    },
                    {"role": "user", "content": text},
                ],
                "temperature": 0.1,
                "max_tokens": 500,
            },
            timeout=30,
        )
        if resp.status_code == 200:
            return resp.json()["choices"][0]["message"]["content"].strip()
        else:
            logger.error(f"ç¿»è­¯ API éŒ¯èª¤: {resp.status_code}")
            return text
    except Exception as e:
        logger.error(f"ç¿»è­¯å¤±æ•—: {e}")
        return text


# ============================================================
# Playwright çˆ¬èŸ²æ ¸å¿ƒ
# ============================================================
class AdidasScraper:
    """ä½¿ç”¨ Playwright çˆ¬å– adidas.jp å•†å“"""

    def __init__(self):
        self.browser = None
        self.context = None
        self.page = None

    async def init_browser(self):
        """å•Ÿå‹•ç€è¦½å™¨"""
        from playwright.async_api import async_playwright

        self.pw = await async_playwright().start()
        launch_args = {
            "headless": True,
            "args": [
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-dev-shm-usage",
                "--disable-blink-features=AutomationControlled",
            ],
        }
        if PROXY_URL:
            launch_args["proxy"] = {"server": PROXY_URL}

        self.browser = await self.pw.chromium.launch(**launch_args)
        self.context = await self.browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent=(
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/120.0.0.0 Safari/537.36"
            ),
            locale="ja-JP",
        )
        self.page = await self.context.new_page()

    async def close_browser(self):
        """é—œé–‰ç€è¦½å™¨"""
        if self.browser:
            await self.browser.close()
        if self.pw:
            await self.pw.stop()

    async def scrape_listing_page(self, category_url: str, max_pages: int = 0) -> list:
        """
        çˆ¬å–å•†å“åˆ—è¡¨é ï¼Œä½¿ç”¨ URL åˆ†é  (?start=0, 48, 96, ...)
        max_pages=0 è¡¨ç¤ºçˆ¬å…¨éƒ¨é é¢
        """
        products = []
        page_num = 0

        while True:
            # çµ„åˆåˆ†é  URL
            if page_num == 0:
                url = category_url
            else:
                start = page_num * ITEMS_PER_PAGE
                separator = "&" if "?" in category_url else "?"
                url = f"{category_url}{separator}start={start}"

            logger.info(f"æ­£åœ¨è¼‰å…¥ç¬¬ {page_num + 1} é : {url}")

            try:
                await self.page.goto(url, wait_until="networkidle", timeout=60000)
                # ç­‰å¾…å•†å“å¡ç‰‡å‡ºç¾
                await self.page.wait_for_selector(
                    '[data-testid="plp-product-card"]', timeout=15000
                )
            except Exception as e:
                logger.info(f"ç¬¬ {page_num + 1} é ç„¡å•†å“æˆ–è¼‰å…¥å¤±æ•—ï¼ŒçµæŸåˆ†é : {e}")
                break

            # é—œé–‰å½ˆçª—ï¼ˆåªåœ¨ç¬¬ä¸€é ï¼‰
            if page_num == 0:
                await self._close_popups()

            # æ»¾å‹•é é¢ç¢ºä¿æ‰€æœ‰å•†å“éƒ½è¼‰å…¥
            await self._scroll_page()

            # è§£æå•†å“å¡ç‰‡
            cards = await self.page.query_selector_all('[data-testid="plp-product-card"]')
            logger.info(f"  ç¬¬ {page_num + 1} é æ‰¾åˆ° {len(cards)} å€‹å•†å“")

            if len(cards) == 0:
                logger.info("æ²’æœ‰æ›´å¤šå•†å“ï¼ŒçµæŸåˆ†é ")
                break

            page_product_count = 0
            for card in cards:
                try:
                    product = await self._parse_card(card)
                    if product:
                        # é¿å…é‡è¤‡ï¼ˆè·¨é å¯èƒ½é‡è¤‡ï¼‰
                        if not any(p["sku"] == product["sku"] for p in products):
                            products.append(product)
                            page_product_count += 1
                except Exception as e:
                    logger.warning(f"è§£æå•†å“å¡ç‰‡å¤±æ•—: {e}")
                    continue

            logger.info(f"  ç¬¬ {page_num + 1} é æ–°å¢ {page_product_count} å€‹å•†å“ï¼ˆç´¯è¨ˆ {len(products)} å€‹ï¼‰")

            # å¦‚æœé€™ä¸€é å•†å“æ•¸å°‘æ–¼ ITEMS_PER_PAGEï¼Œä»£è¡¨æ˜¯æœ€å¾Œä¸€é 
            if len(cards) < ITEMS_PER_PAGE:
                logger.info("å·²åˆ°æœ€å¾Œä¸€é ")
                break

            page_num += 1

            # æª¢æŸ¥æ˜¯å¦é”åˆ°æœ€å¤§é æ•¸é™åˆ¶
            if max_pages > 0 and page_num >= max_pages:
                logger.info(f"å·²é”æœ€å¤§é æ•¸é™åˆ¶ ({max_pages} é )")
                break

            # é é–“å»¶é²
            await self.page.wait_for_timeout(2000)

        logger.info(f"ç¸½å…±æ‰¾åˆ° {len(products)} å€‹ä¸é‡è¤‡å•†å“")
        return products

    async def _scroll_page(self):
        """æ»¾å‹•é é¢ç¢ºä¿æ‰€æœ‰å•†å“éƒ½è¼‰å…¥"""
        for _ in range(5):
            await self.page.evaluate("window.scrollBy(0, window.innerHeight)")
            await self.page.wait_for_timeout(500)
        # æ»¾å›é ‚éƒ¨
        await self.page.evaluate("window.scrollTo(0, 0)")
        await self.page.wait_for_timeout(500)

    async def _parse_card(self, card) -> dict | None:
        """è§£æå–®å€‹å•†å“å¡ç‰‡"""
        # å•†å“é€£çµ
        link_el = await card.query_selector('[data-testid="product-card-image-link"]')
        if not link_el:
            return None
        href = await link_el.get_attribute("href")
        if not href:
            return None

        # å¾ URL å–å¾— SKU (ä¾‹å¦‚ /ã‚µãƒ³ãƒ-og-samba-og/B75806.html â†’ B75806)
        sku_match = re.search(r"/([A-Z0-9]{5,10})\.html", href)
        sku = sku_match.group(1) if sku_match else ""

        # å•†å“åç¨±
        title_el = await card.query_selector('[data-testid="product-card-title"]')
        title = await title_el.inner_text() if title_el else ""

        # å‰¯æ¨™é¡Œï¼ˆç³»åˆ—åï¼‰
        subtitle_el = await card.query_selector('[data-testid="product-card-subtitle"]')
        subtitle = await subtitle_el.inner_text() if subtitle_el else ""

        # åƒ¹æ ¼
        price_el = await card.query_selector('[data-testid="main-price"] span:last-child')
        price_text = await price_el.inner_text() if price_el else ""
        price_jpy = self._parse_price(price_text)

        # é¡è‰²æ•¸
        colors_el = await card.query_selector('[data-testid="product-card-colours"]')
        colors_text = await colors_el.inner_text() if colors_el else ""

        # åœ–ç‰‡
        img_el = await card.query_selector('[data-testid="product-card-primary-image"]')
        img_src = await img_el.get_attribute("src") if img_el else ""
        # å–å¾—é«˜è§£æåº¦åœ–ç‰‡ (æ›¿æ›ç‚º w_840)
        hi_res_img = re.sub(r"w_\d+,h_\d+", "w_840,h_840", img_src) if img_src else ""

        if not sku or not price_jpy:
            return None

        return {
            "sku": sku,
            "title": title,
            "subtitle": subtitle,
            "price_jpy": price_jpy,
            "selling_price": calculate_price(price_jpy),
            "colors_text": colors_text,
            "url": urljoin(BASE_URL, href),
            "image": hi_res_img,
            "scraped_at": datetime.now().isoformat(),
        }

    async def scrape_product_detail(self, product_url: str) -> dict | None:
        """
        çˆ¬å–å•†å“è©³ç´°é ï¼Œå–å¾—å®Œæ•´è³‡è¨Šï¼ˆæè¿°ã€æ‰€æœ‰åœ–ç‰‡ã€å°ºç¢¼ç­‰ï¼‰
        """
        try:
            await self.page.goto(product_url, wait_until="networkidle", timeout=60000)
            await self.page.wait_for_timeout(2000)
        except Exception as e:
            logger.error(f"è¼‰å…¥å•†å“é å¤±æ•—: {product_url} - {e}")
            return None

        detail = {}

        # å•†å“æè¿°
        try:
            desc_el = await self.page.query_selector(
                '[data-testid="product-description"], .pdp-description, [class*="description"]'
            )
            if desc_el:
                detail["description"] = await desc_el.inner_text()
            else:
                detail["description"] = ""
        except Exception:
            detail["description"] = ""

        # æ‰€æœ‰å•†å“åœ–ç‰‡
        try:
            img_elements = await self.page.query_selector_all(
                '[data-testid="pdp-gallery-image"] img, '
                '[class*="gallery"] img, '
                '[class*="slider"] img[src*="assets.adidas.com"]'
            )
            images = []
            seen = set()
            for img in img_elements:
                src = await img.get_attribute("src")
                if src and "assets.adidas.com" in src:
                    # é«˜è§£æåº¦
                    hi_res = re.sub(r"w_\d+,h_\d+", "w_840,h_840", src)
                    if hi_res not in seen:
                        seen.add(hi_res)
                        images.append(hi_res)
            detail["images"] = images
        except Exception:
            detail["images"] = []

        # å¯é¸å°ºç¢¼
        try:
            size_elements = await self.page.query_selector_all(
                '[data-testid="size-selector"] button, '
                '[class*="size"] button[data-testid*="size"]'
            )
            sizes = []
            for btn in size_elements:
                size_text = await btn.inner_text()
                is_disabled = await btn.get_attribute("disabled")
                sizes.append({
                    "size": size_text.strip(),
                    "available": is_disabled is None,
                })
            detail["sizes"] = sizes
        except Exception:
            detail["sizes"] = []

        return detail

    async def _close_popups(self):
        """é—œé–‰å¯èƒ½å‡ºç¾çš„å½ˆçª—"""
        popup_selectors = [
            '[data-testid="cookie-banner-accept"]',
            '[data-testid="modal-close"]',
            'button:has-text("åŒæ„")',
            'button:has-text("é–‰ã˜ã‚‹")',
            'button:has-text("Accept")',
            '[class*="cookie"] button',
            '[class*="popup"] [class*="close"]',
        ]
        for selector in popup_selectors:
            try:
                btn = self.page.locator(selector)
                if await btn.count() > 0:
                    await btn.first.click()
                    await self.page.wait_for_timeout(500)
            except Exception:
                continue

    @staticmethod
    def _parse_price(text: str) -> int:
        """è§£æåƒ¹æ ¼æ–‡å­— 'Â¥15,950' â†’ 15950"""
        if not text:
            return 0
        nums = re.findall(r"\d+", text.replace(",", ""))
        return int("".join(nums)) if nums else 0


# ============================================================
# Shopify ä¸Šæ¶
# ============================================================
class ShopifyUploader:
    """å°‡å•†å“ä¸Šæ¶åˆ° Shopify"""

    def __init__(self):
        if not SHOPIFY_STORE or not SHOPIFY_ACCESS_TOKEN:
            logger.warning("æœªè¨­å®š Shopify ç’°å¢ƒè®Šæ•¸ï¼Œä¸Šæ¶åŠŸèƒ½ä¸å¯ç”¨")
        self.base_url = f"https://{SHOPIFY_STORE}.myshopify.com/admin/api/2024-01"
        self.headers = {
            "X-Shopify-Access-Token": SHOPIFY_ACCESS_TOKEN,
            "Content-Type": "application/json",
        }
        self._existing_skus = None
        self._collection_cache = {}

    def get_existing_skus(self) -> set:
        """å–å¾— Shopify ä¸Šå·²æœ‰çš„æ‰€æœ‰ SKU"""
        if self._existing_skus is not None:
            return self._existing_skus

        skus = set()
        url = f"{self.base_url}/products.json?limit=250&fields=id,variants"
        while url:
            try:
                resp = requests.get(url, headers=self.headers, timeout=30)
                if resp.status_code != 200:
                    logger.error(f"Shopify API éŒ¯èª¤: {resp.status_code}")
                    break
                data = resp.json()
                for product in data.get("products", []):
                    for variant in product.get("variants", []):
                        sku = variant.get("sku", "")
                        if sku:
                            skus.add(sku.upper())

                # åˆ†é 
                link_header = resp.headers.get("Link", "")
                if 'rel="next"' in link_header:
                    import re as _re

                    match = _re.search(r'<([^>]+)>;\s*rel="next"', link_header)
                    url = match.group(1) if match else None
                else:
                    url = None
            except Exception as e:
                logger.error(f"å–å¾— SKU å¤±æ•—: {e}")
                break

        logger.info(f"Shopify å·²æœ‰ {len(skus)} å€‹ SKU")
        self._existing_skus = skus
        return skus

    def is_duplicate(self, sku: str) -> bool:
        """æª¢æŸ¥ SKU æ˜¯å¦å·²å­˜åœ¨"""
        return sku.upper() in self.get_existing_skus()

    def get_or_create_collection(self, title: str) -> int | None:
        """å–å¾—æˆ–å»ºç«‹ Collection"""
        if title in self._collection_cache:
            return self._collection_cache[title]

        # æœå°‹ç¾æœ‰ Collection
        try:
            resp = requests.get(
                f"{self.base_url}/custom_collections.json?title={title}",
                headers=self.headers,
                timeout=30,
            )
            if resp.status_code == 200:
                collections = resp.json().get("custom_collections", [])
                for c in collections:
                    if c["title"] == title:
                        self._collection_cache[title] = c["id"]
                        logger.info(f"æ‰¾åˆ°ç¾æœ‰ Collection: {title} (ID: {c['id']})")
                        return c["id"]
        except Exception:
            pass

        # å»ºç«‹æ–° Collection
        try:
            resp = requests.post(
                f"{self.base_url}/custom_collections.json",
                headers=self.headers,
                json={"custom_collection": {"title": title}},
                timeout=30,
            )
            if resp.status_code == 201:
                cid = resp.json()["custom_collection"]["id"]
                self._collection_cache[title] = cid
                logger.info(f"å»ºç«‹æ–° Collection: {title} (ID: {cid})")
                return cid
        except Exception as e:
            logger.error(f"å»ºç«‹ Collection å¤±æ•—: {e}")

        return None

    def upload_product(
        self,
        product: dict,
        detail: dict | None,
        collection_id: int | None,
        translate: bool = True,
    ) -> dict:
        """ä¸Šæ¶å–®å€‹å•†å“åˆ° Shopify"""
        title = product["title"]
        description = ""

        if detail:
            description = detail.get("description", "")

        # ç¿»è­¯
        if translate and OPENAI_API_KEY:
            title_zh = translate_ja_to_zhtw(title)
            desc_zh = translate_ja_to_zhtw(description) if description else ""
        else:
            title_zh = title
            desc_zh = description

        # çµ„åˆæ¨™é¡Œ: ä¸­æ–‡å + è‹±æ–‡/æ—¥æ–‡åŸå
        if title_zh != title:
            full_title = f"{title_zh} / {title}"
        else:
            full_title = title

        # åœ–ç‰‡
        images = []
        if detail and detail.get("images"):
            for img_url in detail["images"][:10]:  # æœ€å¤š 10 å¼µ
                images.append({"src": img_url})
        elif product.get("image"):
            images.append({"src": product["image"]})

        # çµ„åˆæè¿° HTML
        body_html = self._build_description_html(product, desc_zh)

        # Shopify product payload
        payload = {
            "product": {
                "title": full_title,
                "body_html": body_html,
                "vendor": "adidas",
                "product_type": "é‹é¡",
                "tags": [
                    "adidas",
                    product.get("subtitle", ""),
                    product["sku"],
                ],
                "variants": [
                    {
                        "price": str(product["selling_price"]),
                        "compare_at_price": None,
                        "sku": product["sku"],
                        "inventory_management": None,
                        "requires_shipping": True,
                    }
                ],
                "images": images,
                "status": "active",
            }
        }

        try:
            resp = requests.post(
                f"{self.base_url}/products.json",
                headers=self.headers,
                json=payload,
                timeout=60,
            )
            if resp.status_code == 201:
                shopify_product = resp.json()["product"]
                product_id = shopify_product["id"]
                logger.info(
                    f"âœ… ä¸Šæ¶æˆåŠŸ: {product['sku']} - {title} â†’ Â¥{product['selling_price']}"
                )

                # åŠ å…¥ Collection
                if collection_id:
                    self._add_to_collection(product_id, collection_id)

                self._existing_skus.add(product["sku"].upper())
                return {"success": True, "product_id": product_id}
            else:
                logger.error(f"âŒ ä¸Šæ¶å¤±æ•—: {product['sku']} - {resp.status_code} {resp.text[:200]}")
                return {"success": False, "error": resp.text[:200]}
        except Exception as e:
            logger.error(f"âŒ ä¸Šæ¶ç•°å¸¸: {product['sku']} - {e}")
            return {"success": False, "error": str(e)}

    def _add_to_collection(self, product_id: int, collection_id: int):
        """å°‡å•†å“åŠ å…¥ Collection"""
        try:
            requests.post(
                f"{self.base_url}/collects.json",
                headers=self.headers,
                json={
                    "collect": {
                        "product_id": product_id,
                        "collection_id": collection_id,
                    }
                },
                timeout=30,
            )
        except Exception:
            pass

    @staticmethod
    def _build_description_html(product: dict, description_zh: str) -> str:
        """çµ„åˆå•†å“æè¿° HTML"""
        parts = []

        if description_zh:
            parts.append(f"<p>{description_zh}</p>")

        parts.append("<hr>")
        parts.append("<table>")
        parts.append(f'<tr><td><strong>å“ç‰Œ</strong></td><td>adidas</td></tr>')
        parts.append(
            f'<tr><td><strong>ç³»åˆ—</strong></td><td>{product.get("subtitle", "")}</td></tr>'
        )
        parts.append(f'<tr><td><strong>å‹è™Ÿ</strong></td><td>{product["sku"]}</td></tr>')
        parts.append(
            f'<tr><td><strong>æ—¥æœ¬å®˜ç¶²å”®åƒ¹</strong></td><td>Â¥{product["price_jpy"]:,}</td></tr>'
        )
        parts.append("</table>")
        parts.append("<hr>")
        parts.append(
            f'<p><small>ğŸ“ <a href="{product["url"]}" target="_blank">'
            f"adidas.jp å®˜ç¶²é€£çµ</a></small></p>"
        )

        return "\n".join(parts)
