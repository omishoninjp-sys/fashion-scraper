"""
Human Made å•†å“çˆ¬èŸ² + Shopify ä¸Šæ¶å·¥å…· v3.0
===========================================
v3.0 é‡å¤§æ”¹ç‰ˆï¼šhumanmade.jp å·²å¾ Shopify é·ç§»åˆ°è‡ªå»ºå¹³å°
- ä½¿ç”¨ Playwright (Chromium) çœŸå¯¦ç€è¦½å™¨ç¹é WAF/403 å°é–
- æ””æˆªç¶²è·¯è«‹æ±‚è‡ªå‹•åµæ¸¬ API ç«¯é»
- å¾ HTML è§£æå•†å“è³‡æ–™ï¼ˆå•†å“åã€åƒ¹æ ¼ã€é¡è‰²ã€å°ºå¯¸ã€åœ–ç‰‡ç­‰ï¼‰
- ä¿ç•™ Shopify ä¸Šæ¶é‚è¼¯ + å®‰å…¨æ©Ÿåˆ¶ï¼ˆé˜²èª¤åˆªï¼‰
- æ”¯æ´ GraphQL æ‰¹æ¬¡æŸ¥è©¢ + Rate Limit ä¿è­·
"""

from flask import Flask, jsonify
import requests
import re
import json
import os
import time
import threading
import asyncio
from urllib.parse import urljoin
from dotenv import load_dotenv

# è¼‰å…¥ .env æª”æ¡ˆ
load_dotenv()

app = Flask(__name__)

# ========== è¨­å®š ==========
SHOPIFY_SHOP = ""
SHOPIFY_ACCESS_TOKEN = ""
SOURCE_URL = "https://www.humanmade.jp"
# ç”¨æ—¥æ–‡ç‰ˆå–å¾— JPY åƒ¹æ ¼
ALL_ITEMS_URL = "https://www.humanmade.jp/all/"
ALL_ITEMS_URL_EN = "https://www.humanmade.jp/en/all/"
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
MIN_PRICE = 1000
DEFAULT_WEIGHT = 0.5
# å®‰å…¨æ©Ÿåˆ¶ï¼šä¾†æºå•†å“å°‘æ–¼æ­¤æ•¸é‡æ™‚è·³éåˆªé™¤
MIN_PRODUCTS_FOR_CLEANUP = 10

HEADERS_BROWSER = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ja,en;q=0.9',
}

scrape_status = {
    "running": False, "progress": 0, "total": 0, "current_product": "",
    "products": [], "errors": [], "uploaded": 0, "skipped": 0,
    "skipped_exists": 0, "filtered_by_price": 0, "out_of_stock": 0,
    "deleted": 0, "price_updated": 0
}
status_lock = threading.Lock()
_token_loaded = False


# ========== Shopify Token ==========

def load_shopify_token():
    global SHOPIFY_ACCESS_TOKEN, SHOPIFY_SHOP, _token_loaded
    if _token_loaded:
        return True
    env_token = os.environ.get('SHOPIFY_ACCESS_TOKEN', '')
    env_shop = os.environ.get('SHOPIFY_SHOP', '')
    if env_token and env_shop:
        SHOPIFY_ACCESS_TOKEN = env_token
        SHOPIFY_SHOP = env_shop.replace('https://', '').replace('http://', '').replace('.myshopify.com', '').strip('/')
        _token_loaded = True
        return True
    tf = "shopify_token.json"
    if os.path.exists(tf):
        with open(tf, 'r') as f:
            d = json.load(f)
            SHOPIFY_ACCESS_TOKEN = d.get('access_token', '')
            s = d.get('shop', '')
            if s:
                SHOPIFY_SHOP = s.replace('https://', '').replace('http://', '').replace('.myshopify.com', '').strip('/')
            _token_loaded = True
            return True
    return False


def get_shopify_headers():
    return {'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN, 'Content-Type': 'application/json'}


def shopify_api_url(endpoint):
    return f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/{endpoint}"


# ========== Shopify APIï¼ˆå« Rate Limitï¼‰==========

def shopify_request(method, url, max_retries=3, **kwargs):
    headers = kwargs.pop('headers', None) or get_shopify_headers()
    for attempt in range(max_retries):
        try:
            r = requests.request(method, url, headers=headers, timeout=30, **kwargs)
            if r.status_code == 429:
                retry_after = float(r.headers.get('Retry-After', 2.0))
                print(f"[RATE LIMIT] 429, waiting {retry_after}s")
                time.sleep(retry_after)
                continue
            call_limit = r.headers.get('X-Shopify-Shop-Api-Call-Limit', '')
            if call_limit:
                parts = call_limit.split('/')
                if len(parts) == 2 and int(parts[1]) - int(parts[0]) < 4:
                    time.sleep(1.0)
            return r
        except Exception as e:
            print(f"[REQUEST ERROR] {e} (attempt {attempt+1})")
            time.sleep(2)
    class FakeResponse:
        status_code = 500
        text = "Max retries exceeded"
        headers = {}
        def json(self): return {}
    return FakeResponse()


def shopify_graphql(query, variables=None):
    url = f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/graphql.json"
    headers = {'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN, 'Content-Type': 'application/json'}
    payload = {'query': query}
    if variables:
        payload['variables'] = variables
    for attempt in range(3):
        try:
            r = requests.post(url, headers=headers, json=payload, timeout=30)
            if r.status_code == 429:
                time.sleep(float(r.headers.get('Retry-After', 2.0)))
                continue
            if r.status_code == 200:
                data = r.json()
                errors = data.get('errors', [])
                if errors and any('Throttled' in str(e) for e in errors):
                    time.sleep(2)
                    continue
                return data
        except Exception as e:
            print(f"[GQL ERROR] {e}")
            time.sleep(2)
    return {'errors': ['Max retries exceeded']}


def calculate_selling_price(cost, weight):
    if not cost or cost <= 0:
        return 0
    weight = weight if weight and weight > 0 else DEFAULT_WEIGHT
    return round((cost + weight * 1250) / 0.7)


# ========== ç¿»è­¯ ==========

def translate_with_chatgpt(title, description, max_retries=2):
    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹æ—¥æœ¬æœé£¾å“ç‰Œå•†å“è³‡è¨Šç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼Œä¸¦å„ªåŒ– SEOã€‚

å•†å“åç¨±ï¼ˆæ—¥æ–‡/è‹±æ–‡ï¼‰ï¼š{title}
å•†å“èªªæ˜ï¼š{description[:1500] if description else ''}

è«‹å›å‚³ JSON æ ¼å¼ï¼ˆä¸è¦åŠ  markdown æ¨™è¨˜ï¼‰ï¼š
{{"title":"ç¿»è­¯å¾Œçš„å•†å“åç¨±ï¼ˆå‰é¢åŠ ä¸Š Human Madeï¼‰","description":"ç¿»è­¯å¾Œçš„å•†å“èªªæ˜ï¼ˆHTMLï¼Œç”¨<br>æ›è¡Œï¼‰","page_title":"SEOæ¨™é¡Œ50-60å­—","meta_description":"SEOæè¿°100å­—å…§"}}

è¦å‰‡ï¼š1. Human Made æ½®æµå“ç‰Œ 2. é–‹é ­ã€ŒHuman Madeã€3. ç¦æ—¥æ–‡ 4. è‡ªç„¶æµæš¢ 5. åªå›å‚³JSON"""

    for attempt in range(max_retries):
        try:
            r = requests.post("https://api.openai.com/v1/chat/completions",
                headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"},
                json={"model": "gpt-4o-mini", "messages": [
                    {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚è¼¸å‡ºç¦æ­¢ä»»ä½•æ—¥æ–‡å­—å…ƒã€‚"},
                    {"role": "user", "content": prompt}], "temperature": 0, "max_tokens": 1000}, timeout=60)
            if r.status_code == 200:
                c = r.json()['choices'][0]['message']['content'].strip()
                if c.startswith('```'):
                    c = c.split('\n', 1)[1]
                if c.endswith('```'):
                    c = c.rsplit('```', 1)[0]
                t = json.loads(c.strip())
                tt = t.get('title', title)
                if not tt.startswith('Human Made'):
                    tt = f"Human Made {tt}"
                return {'success': True, 'title': tt, 'description': t.get('description', description),
                        'page_title': t.get('page_title', ''), 'meta_description': t.get('meta_description', '')}
            elif r.status_code == 429:
                time.sleep(5)
                continue
        except json.JSONDecodeError:
            continue
        except Exception as e:
            print(f"[ç¿»è­¯éŒ¯èª¤] {e}")
            break

    return {'success': False, 'title': f"Human Made {title}", 'description': description,
            'page_title': '', 'meta_description': ''}


# ========== Playwright çˆ¬èŸ²æ ¸å¿ƒ ==========

async def scrape_all_products_playwright():
    """
    ä½¿ç”¨ Playwright çœŸå¯¦ç€è¦½å™¨çˆ¬å– humanmade.jp æ‰€æœ‰å•†å“
    ç­–ç•¥ï¼š
    1. é–‹å•Ÿå•†å“åˆ—è¡¨é ï¼Œæ””æˆªç¶²è·¯è«‹æ±‚æ‰¾ API
    2. æ»¾å‹•è¼‰å…¥æ‰€æœ‰å•†å“å¡ç‰‡
    3. æ”¶é›†å•†å“é€£çµ
    4. é€ä¸€é€²å…¥å•†å“é é¢è§£æè©³ç´°è³‡æ–™
    """
    from playwright.async_api import async_playwright

    products = []
    api_responses = []  # æ””æˆªåˆ°çš„ API å›æ‡‰

    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
        )
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            locale='ja-JP',
            extra_http_headers={
                'Accept-Language': 'ja,en;q=0.9',
            }
        )

        # === Phase 1: å–å¾—å•†å“åˆ—è¡¨ ===
        page = await context.new_page()

        # æ””æˆª API è«‹æ±‚ï¼ˆè‡ªå‹•åµæ¸¬å¾Œç«¯ APIï¼‰
        async def handle_response(response):
            url = response.url
            if any(kw in url for kw in ['products', 'items', 'catalog', 'api', 'graphql']):
                try:
                    ct = response.headers.get('content-type', '')
                    if 'json' in ct:
                        body = await response.json()
                        api_responses.append({'url': url, 'data': body})
                        print(f"[API æ””æˆª] {url[:100]}")
                except:
                    pass

        page.on('response', handle_response)

        print("[Phase 1] è¼‰å…¥å•†å“åˆ—è¡¨é é¢...")
        update_status(current_product="è¼‰å…¥å•†å“åˆ—è¡¨é é¢...")

        try:
            await page.goto(ALL_ITEMS_URL, wait_until='networkidle', timeout=60000)
        except Exception as e:
            print(f"[WARNING] networkidle timeout, continuing... {e}")
            await page.wait_for_timeout(5000)

        # === é—œé–‰ Cookie å½ˆçª— ===
        try:
            cookie_btn = page.locator('text=åŒæ„ã™ã‚‹').first
            if await cookie_btn.is_visible(timeout=3000):
                await cookie_btn.click()
                print("[Phase 1] âœ“ å·²é—œé–‰ Cookie å½ˆçª—")
                await page.wait_for_timeout(1000)
        except:
            pass

        # === é—œé–‰ Global-e åœ‹éš›é‹é€å½ˆçª— ===
        try:
            await page.evaluate('''() => {
                const ge = document.getElementById('globalePopupWrapper');
                if (ge) ge.remove();
                document.querySelectorAll('[class*="globale"], [id*="globale"]').forEach(el => {
                    if (getComputedStyle(el).position === 'fixed') el.remove();
                });
            }''')
            print("[Phase 1] âœ“ å·²ç§»é™¤ Global-e å½ˆçª—")
            await page.wait_for_timeout(1000)
        except:
            pass

        # === é»æ“Š VIEW MORE è¼‰å…¥æ‰€æœ‰å•†å“ ===
        print("[Phase 1] é»æ“Š VIEW MORE è¼‰å…¥æ‰€æœ‰å•†å“...")
        update_status(current_product="é»æ“Š VIEW MORE è¼‰å…¥æ‰€æœ‰å•†å“...")

        for click_round in range(50):  # æœ€å¤šé» 50 æ¬¡
            try:
                # å…ˆæ»¾åˆ°åº•éƒ¨è®“æŒ‰éˆ•å¯è¦‹
                await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                await page.wait_for_timeout(1500)

                # æ¸…é™¤å¯èƒ½æ–°å‡ºç¾çš„å½ˆçª—
                await page.evaluate('''() => {
                    const ge = document.getElementById('globalePopupWrapper');
                    if (ge) ge.remove();
                }''')

                # æ‰¾ VIEW MORE æŒ‰éˆ•
                view_more = page.locator('button.show-more').first
                if await view_more.is_visible(timeout=3000):
                    await view_more.click(force=True)
                    count = await page.evaluate('''() => {
                        const ids = new Set();
                        document.querySelectorAll('a[href]').forEach(a => {
                            const m = a.href.match(/\\/[^\\/]+\\/([A-Z][A-Z0-9]+)\\.html/);
                            if (m) ids.add(m[1]);
                        });
                        return ids.size;
                    }''')
                    print(f"[Phase 1] VIEW MORE ç¬¬ {click_round + 1} æ¬¡ï¼Œç›®å‰ {count} å€‹å•†å“")
                    await page.wait_for_timeout(3000)
                else:
                    print(f"[Phase 1] æ²’æœ‰æ›´å¤š VIEW MORE æŒ‰éˆ•ï¼Œè¼‰å…¥å®Œæˆ")
                    break
            except Exception as e:
                print(f"[Phase 1] VIEW MORE é»æ“ŠçµæŸ: {e}")
                break

        # æ”¶é›†å•†å“é€£çµ
        product_links = await page.evaluate('''() => {
            const links = new Map();  // item_id -> category_path
            // æ’é™¤éå•†å“é é¢ï¼ˆç´”å°å¯«+é€£å­—è™Ÿçš„æ˜¯è³‡è¨Šé ï¼‰
            const excludePages = ['about', 'faq', 'shipping', 'payment', 'privacy', 'terms', 'inquiries', 'dealers', 'legal', 'counterfeit', 'maintenance'];
            document.querySelectorAll('a[href]').forEach(a => {
                const href = a.getAttribute('href') || '';
                // åŒ¹é…: /{category}/{ITEM_ID}.html å…¶ä¸­ ITEM_ID ä»¥å¤§å¯«å­—æ¯é–‹é ­
                const match = href.match(/\\/([^\\/]+)\\/([A-Z][A-Z0-9]+)\\.html/);
                if (match) {
                    const category = match[1];
                    const itemId = match[2];
                    // æ’é™¤éå•†å“é 
                    if (!excludePages.some(ex => category.includes(ex)) && !excludePages.some(ex => itemId.toLowerCase().includes(ex))) {
                        links.set(itemId, category);
                    }
                }
            });
            return Array.from(links.entries());  // [[itemId, category], ...]
        }''')

        print(f"[Phase 1] å…±æ‰¾åˆ° {len(product_links)} å€‹ä¸é‡è¤‡å•†å“ ID")

        # å¦‚æœæœ‰æ””æˆªåˆ° APIï¼Œå˜—è©¦å¾ä¸­å–å¾—çµæ§‹åŒ–è³‡æ–™
        if api_responses:
            print(f"[API] æ””æˆªåˆ° {len(api_responses)} å€‹ API å›æ‡‰ï¼Œå˜—è©¦è§£æ...")
            for api_resp in api_responses:
                print(f"  - {api_resp['url'][:120]}")
                # å„²å­˜ä»¥ä¾¿é™¤éŒ¯
                try:
                    with open('/tmp/humanmade_api_responses.json', 'w') as f:
                        json.dump(api_responses, f, ensure_ascii=False, indent=2, default=str)
                except:
                    pass

        # === Phase 2: é€ä¸€çˆ¬å–å•†å“è©³æƒ… ===
        print(f"\n[Phase 2] é–‹å§‹çˆ¬å– {len(product_links)} å€‹å•†å“è©³æƒ…...")
        update_status(total=len(product_links))

        consecutive_failures = 0
        MAX_CONSECUTIVE_FAILURES = 5

        for idx, (item_id, category) in enumerate(product_links):
            update_status(progress=idx + 1, current_product=f"çˆ¬å–å•†å“: {item_id}")

            product_url = f"{SOURCE_URL}/{category}/{item_id}.html"
            product_data = None

            # é‡è©¦æœ€å¤š 2 æ¬¡
            for retry in range(2):
                product_data = await scrape_product_page(page, product_url, item_id)
                if product_data:
                    break
                print(f"  [RETRY] {item_id} ç¬¬ {retry+1} æ¬¡é‡è©¦...")
                await page.wait_for_timeout(3000)

            if product_data:
                product_data['category_path'] = category
                products.append(product_data)
                print(f"[{idx+1}/{len(product_links)}] âœ“ {item_id}: {product_data.get('title', 'N/A')} - Â¥{product_data.get('price_jpy', 0)}")
                consecutive_failures = 0
            else:
                print(f"[{idx+1}/{len(product_links)}] âœ— {item_id}: è§£æå¤±æ•—")
                consecutive_failures += 1

            # é€£çºŒå¤±æ•—å¤ªå¤šæ¬¡ â†’ é‡å•Ÿç€è¦½å™¨
            if consecutive_failures >= MAX_CONSECUTIVE_FAILURES:
                print(f"[âš ï¸] é€£çºŒ {MAX_CONSECUTIVE_FAILURES} æ¬¡å¤±æ•—ï¼Œé‡å•Ÿç€è¦½å™¨...")
                try:
                    await page.close()
                    await context.close()
                    await browser.close()
                except:
                    pass
                browser = await p.chromium.launch(
                    headless=True,
                    args=['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
                )
                context = await browser.new_context(
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    locale='ja-JP',
                    extra_http_headers={'Accept-Language': 'ja,en;q=0.9'}
                )
                page = await context.new_page()
                consecutive_failures = 0
                print(f"[âœ“] ç€è¦½å™¨å·²é‡å•Ÿ")

            # æ§é€Ÿé¿å…è¢«å°
            await page.wait_for_timeout(1500)

        await browser.close()

    print(f"\n[å®Œæˆ] å…±æˆåŠŸçˆ¬å– {len(products)} å€‹å•†å“")
    return products


async def scrape_product_page(page, url, item_id):
    """è§£æå–®ä¸€å•†å“é é¢"""
    try:
        await page.goto(url, wait_until='networkidle', timeout=30000)
    except Exception as e:
        try:
            # networkidle timeout ä½†é é¢å¯èƒ½å·²è¼‰å…¥
            await page.wait_for_timeout(3000)
        except:
            return None

    # æ¯æ¬¡é€²å…¥å•†å“é éƒ½æ¸…é™¤å¯èƒ½çš„å½ˆçª—
    try:
        await page.evaluate('''() => {
            const ge = document.getElementById('globalePopupWrapper');
            if (ge) ge.remove();
        }''')
    except:
        pass

    try:
        data = await page.evaluate('''() => {
            const result = {
                title: '',
                description: '',
                price_text: '',
                colors: [],
                sizes: [],
                images: [],
                item_id: '',
                material: '',
                made_in: '',
                available: true,
                url: window.location.href
            };

            // === å•†å“åç¨± ===
            // å˜—è©¦å¤šç¨® selector
            const titleSelectors = [
                'h1', '.product-title', '.product-name',
                '[class*="product"] h1', '[class*="item"] h1',
                'h2.product', 'main h1'
            ];
            for (const sel of titleSelectors) {
                const el = document.querySelector(sel);
                if (el && el.textContent.trim().length > 2) {
                    result.title = el.textContent.trim();
                    break;
                }
            }

            // === åƒ¹æ ¼ï¼ˆå–å¾—æ—¥åœ“åƒ¹æ ¼ï¼‰===
            const priceSelectors = [
                '.prices .price .value', '.sales .value',  // SFCC å¸¸è¦‹
                '[class*="price"]', '.product-price', '.price',
                '[data-price]'
            ];
            const allElements = document.querySelectorAll('*');
            for (const el of allElements) {
                const text = el.textContent.trim();
                // æ‰¾åŒ…å« Â¥ æˆ– NT$ çš„å…ƒç´ 
                if (text.match(/[Â¥ï¿¥]\\s*[\\d,]+/) && el.children.length < 3) {
                    result.price_text = text;
                    break;
                }
                if (text.match(/NT\\$\\s*[\\d,]+/) && el.children.length < 3) {
                    result.price_text = text;
                    break;
                }
            }

            // === é¡è‰² ===
            const colorLabels = document.querySelectorAll(
                '[class*="color"] label, [class*="color"] span, ' +
                '[class*="Color"] span, [data-option="color"] span'
            );
            colorLabels.forEach(el => {
                const text = el.textContent.trim();
                if (text && text.length < 30 && !text.match(/^(Color|è‰²|ã‚«ãƒ©ãƒ¼)$/i)) {
                    result.colors.push(text);
                }
            });
            // ä¹Ÿå¾åœ–ç‰‡ alt å˜—è©¦
            if (result.colors.length === 0) {
                document.querySelectorAll('[class*="color"] img, [class*="swatch"] img').forEach(img => {
                    const alt = img.alt || img.title || '';
                    if (alt) result.colors.push(alt.trim());
                });
            }

            // === å°ºå¯¸ ===
            const sizeElements = document.querySelectorAll(
                '[class*="size"] button, [class*="size"] label, ' +
                '[class*="Size"] button, [class*="Size"] label, ' +
                '[data-option="size"] button, [data-option="size"] label'
            );
            sizeElements.forEach(el => {
                const text = el.textContent.trim();
                if (text && text.length < 10 && text.match(/^(XXS|XS|S|M|L|XL|2XL|3XL|ONE SIZE|FREE|\\d+)$/i)) {
                    result.sizes.push(text);
                }
            });

            // === åœ–ç‰‡ ===
            // SFCC/Demandware å¸¸è¦‹çš„å•†å“åœ–ç‰‡å®¹å™¨
            const imageSelectors = [
                '.product-detail img', '.pdp-main img',
                '.product-images img', '.product-gallery img',
                '[class*="carousel"] img', '[class*="slider"] img',
                '[class*="gallery"] img', '[class*="product"] img',
                '.primary-images img', '.pdp-images img',
                'main img[src]', '.container img[src]'
            ];
            const seenSrc = new Set();
            // æ’é™¤çš„é—œéµå­—
            const excludePatterns = ['icon', 'logo', 'svg', 'pixel', 'tracking', 'spacer', 'blank', 'globale', 'banner', 'badge', 'flag', 'payment'];
            
            for (const sel of imageSelectors) {
                document.querySelectorAll(sel).forEach(img => {
                    let src = img.src || img.dataset.src || img.dataset.lazySrc || img.dataset.highresSrc || '';
                    // ä¹Ÿæª¢æŸ¥ srcset
                    if (!src && img.srcset) {
                        const firstSrc = img.srcset.split(',')[0].trim().split(' ')[0];
                        if (firstSrc) src = firstSrc;
                    }
                    if (src && !seenSrc.has(src)) {
                        const srcLower = src.toLowerCase();
                        const isExcluded = excludePatterns.some(p => srcLower.includes(p));
                        // æ’é™¤å¤ªå°çš„åœ–ï¼ˆé€šå¸¸æ˜¯ iconï¼‰å’Œ data: URI
                        if (!isExcluded && !src.startsWith('data:') && src.startsWith('http')) {
                            seenSrc.add(src);
                            result.images.push(src);
                        }
                    }
                });
                if (result.images.length >= 3) break;  // æ‰¾åˆ° 3+ å¼µå°±å¤ äº†
            }
            // Fallback: æ‹¿æ‰€æœ‰å¤§åœ–
            if (result.images.length === 0) {
                document.querySelectorAll('img').forEach(img => {
                    const src = img.src || img.dataset.src || '';
                    if (src && src.startsWith('http') && !seenSrc.has(src)) {
                        const srcLower = src.toLowerCase();
                        const isExcluded = excludePatterns.some(p => srcLower.includes(p));
                        if (!isExcluded && (img.naturalWidth > 200 || img.width > 200 || !img.complete)) {
                            seenSrc.add(src);
                            result.images.push(src);
                        }
                    }
                });
            }
            
            // Debug: è¨˜éŒ„æ‰€æœ‰ img src ä¾›è¨ºæ–·
            result.debug_all_imgs = [];
            document.querySelectorAll('img').forEach(img => {
                const src = img.src || img.dataset.src || '';
                if (src && src.startsWith('http')) {
                    result.debug_all_imgs.push({
                        src: src.substring(0, 150),
                        w: img.naturalWidth || img.width || 0,
                        cls: (img.className || '').substring(0, 50),
                        parent: (img.parentElement?.className || '').substring(0, 50)
                    });
                }
            });

            // === å•†å“èªªæ˜ / ITEM ID / MATERIAL ===
            const bodyText = document.body.innerText;
            const itemIdMatch = bodyText.match(/ITEM\\s*ID[ï¼š:]\\s*([A-Z0-9]+)/i);
            if (itemIdMatch) result.item_id = itemIdMatch[1];

            const materialMatch = bodyText.match(/MATERIAL[ï¼š:]\\s*([^\\n]+)/i);
            if (materialMatch) result.material = materialMatch[1].trim();

            const madeInMatch = bodyText.match(/MADE\\s+IN\\s+([A-Z]+)/i);
            if (madeInMatch) result.made_in = madeInMatch[1].trim();

            // å•†å“èªªæ˜ï¼ˆå– product description å€å¡Šï¼‰
            // SFCC çš„èªªæ˜æ–‡åœ¨ #collapsible-description-1 è£¡
            const descSelectors = [
                '#collapsible-description-1 p',
                '#collapsible-description-1',
                '.value.content p',
                '.value.content',
                '.product-description .description-text',
                '.product-description .content',
                '.product-description p',
                '.product-description',
                '.description-and-detail .description',
                '.pdp-description',
            ];
            for (const sel of descSelectors) {
                const el = document.querySelector(sel);
                if (el) {
                    const text = el.innerText.trim();
                    if (text.length > 20) {
                        result.description = text;
                        break;
                    }
                }
            }
            // Fallback: å¾é é¢æ–‡å­—ä¸­æ‰¾ ITEM ID é™„è¿‘çš„èªªæ˜æ–‡
            if (!result.description) {
                const bodyText = document.body.innerText;
                // æ‰¾ ITEM ID å‰é¢çš„æ®µè½ä½œç‚ºèªªæ˜
                const itemIdIdx = bodyText.indexOf('ITEM ID');
                if (itemIdIdx > 0) {
                    // å¾€å‰æ‰¾ä¸€æ®µæ–‡å­—
                    const beforeText = bodyText.substring(Math.max(0, itemIdIdx - 500), itemIdIdx).trim();
                    const lines = beforeText.split('\\n').filter(l => l.trim().length > 10);
                    if (lines.length > 0) {
                        result.description = lines.join('\\n');
                    }
                }
            }
            // Debug
            result.debug_desc_length = (result.description || '').length;
            result.debug_desc_preview = (result.description || '').substring(0, 200);

            // === æ˜¯å¦å¯è³¼è²· ===
            const soldOutEl = document.querySelector(
                '[class*="sold-out"], [class*="soldout"], .notify-me'
            );
            if (soldOutEl) {
                result.available = false;
            }
            // æª¢æŸ¥æŒ‰éˆ•æ–‡å­—åˆ¤æ–·æ˜¯å¦ç‚º NOTIFY ME / SOLD OUT
            const allButtons = document.querySelectorAll('button, a.btn, [role="button"]');
            for (const btn of allButtons) {
                const txt = btn.textContent.trim().toUpperCase();
                if (txt.includes('NOTIFY') || txt.includes('SOLD OUT') || txt.includes('å“åˆ‡ã‚Œ')) {
                    result.available = false;
                    if (txt.includes('NOTIFY')) result.notify_me = true;
                    break;
                }
            }

            return result;
        }''')

        if not data or not data.get('title'):
            return None

        # Debug: å°å‡ºåœ–ç‰‡è¨ºæ–·è³‡è¨Š
        debug_imgs = data.pop('debug_all_imgs', [])
        debug_desc = data.pop('debug_desc_preview', '')
        debug_desc_len = data.pop('debug_desc_length', 0)
        
        print(f"  [DESC] {item_id}: èªªæ˜æ–‡ {debug_desc_len} å­— - {debug_desc[:100]}")
        
        if len(data.get('images', [])) == 0:
            print(f"  [IMG DEBUG] {item_id}: æ²’æŠ“åˆ°å•†å“åœ–ç‰‡ï¼é é¢ä¸Šæ‰€æœ‰ img:")
            for di in debug_imgs[:15]:
                print(f"    {di['src']} (w={di['w']}, class={di['cls']}, parent={di['parent']})")
        else:
            print(f"  [IMG] {item_id}: æŠ“åˆ° {len(data.get('images', []))} å¼µåœ–ç‰‡")
            for img in data['images'][:3]:
                print(f"    {img[:120]}")

        # è§£æåƒ¹æ ¼ï¼ˆå¾æ—¥åœ“æˆ–å°å¹£æ–‡å­—ï¼‰
        price_jpy = 0
        price_text = data.get('price_text', '')
        # å˜—è©¦æå– JPY
        jpy_match = re.search(r'[Â¥ï¿¥]\s*([\d,]+)', price_text)
        if jpy_match:
            price_jpy = int(jpy_match.group(1).replace(',', ''))
        else:
            # NT$ â†’ å¤§ç´„æ›ç®—å› JPYï¼ˆåƒ…ç”¨æ–¼åƒ¹æ ¼é–€æª»åˆ¤æ–·ï¼Œå¯¦éš›ä¸Šæ¶ç”¨ JPYï¼‰
            ntd_match = re.search(r'NT\$\s*([\d,]+)', price_text)
            if ntd_match:
                ntd = int(ntd_match.group(1).replace(',', ''))
                price_jpy = int(ntd * 4.5)  # å¤§ç´„åŒ¯ç‡

        data['price_jpy'] = price_jpy
        data['item_id'] = data.get('item_id') or item_id
        data['handle'] = item_id  # ç”¨ item_id ç•¶ handle

        # åƒ¹æ ¼åˆç†æ€§æª¢æŸ¥ï¼ˆJPY é€šå¸¸ > 1000ï¼‰
        if price_jpy > 0 and price_jpy < 500:
            print(f"  [âš ï¸ åƒ¹æ ¼] {item_id}: Â¥{price_jpy} å¯èƒ½ä¸æ˜¯æ—¥åœ“ï¼ˆNTD?ï¼‰ï¼ŒåŸå§‹: {price_text}")

        return data

    except Exception as e:
        print(f"[è§£æéŒ¯èª¤] {url}: {e}")
        return None


# ========== Shopify å·¥å…·å‡½æ•¸ ==========

def get_collection_products_with_details(collection_id):
    """GraphQL æ‰¹æ¬¡æŸ¥è©¢"""
    products_map = {}
    if not collection_id:
        return products_map

    query = """
    query($collectionId: ID!, $cursor: String) {
      collection(id: $collectionId) {
        products(first: 50, after: $cursor) {
          pageInfo { hasNextPage endCursor }
          edges {
            node {
              id handle
              variants(first: 100) {
                edges {
                  node {
                    id price sku
                    selectedOptions { name value }
                    inventoryItem { unitCost { amount } }
                  }
                }
              }
            }
          }
        }
      }
    }
    """
    cursor = None
    while True:
        data = shopify_graphql(query, {
            "collectionId": f"gid://shopify/Collection/{collection_id}",
            "cursor": cursor
        })
        collection = data.get('data', {}).get('collection')
        if not collection:
            break
        products_data = collection.get('products', {})
        for edge in products_data.get('edges', []):
            node = edge['node']
            product_id = int(node['id'].split('/')[-1])
            handle = node['handle']
            variants_info = []
            for ve in node.get('variants', {}).get('edges', []):
                vn = ve['node']
                variant_id = int(vn['id'].split('/')[-1])
                cost = None
                uc = (vn.get('inventoryItem') or {}).get('unitCost')
                if uc:
                    cost = uc.get('amount')
                opts = vn.get('selectedOptions', [])
                variants_info.append({
                    'variant_id': variant_id, 'price': vn.get('price'), 'cost': cost,
                    'sku': vn.get('sku'),
                    'option1': opts[0]['value'] if len(opts) > 0 else '',
                    'option2': opts[1]['value'] if len(opts) > 1 else '',
                    'option3': opts[2]['value'] if len(opts) > 2 else ''
                })
            products_map[handle] = {'product_id': product_id, 'variants': variants_info}
        page_info = products_data.get('pageInfo', {})
        if page_info.get('hasNextPage'):
            cursor = page_info['endCursor']
            time.sleep(0.5)
        else:
            break
    print(f"[INFO] Collection å…§æœ‰ {len(products_map)} å€‹å•†å“")
    return products_map


def delete_product(product_id):
    r = shopify_request('DELETE', shopify_api_url(f"products/{product_id}.json"))
    if r.status_code == 200:
        print(f"[å·²åˆªé™¤] Product ID: {product_id}")
        return True
    return False


def publish_to_channels(resource_type, resource_id):
    """ç™¼ä½ˆåˆ°æ‰€æœ‰éŠ·å”®é »é“"""
    data = shopify_graphql('{ publications(first:20){ edges{ node{ id name }}}}')
    pubs = data.get('data', {}).get('publications', {}).get('edges', [])
    seen = set()
    uq = []
    for p in pubs:
        if p['node']['name'] not in seen:
            seen.add(p['node']['name'])
            uq.append(p['node'])
    mut = """mutation publishablePublish($id:ID!,$input:[PublicationInput!]!){
        publishablePublish(id:$id,input:$input){userErrors{field message}}}"""
    shopify_graphql(mut, {
        "id": f"gid://shopify/{resource_type}/{resource_id}",
        "input": [{"publicationId": p['id']} for p in uq]
    })


def get_or_create_collection(ct="Human Made"):
    r = shopify_request('GET', shopify_api_url(f'custom_collections.json?title={ct}'))
    if r.status_code == 200:
        for c in r.json().get('custom_collections', []):
            if c['title'] == ct:
                publish_to_channels('Collection', c['id'])
                return c['id']
    r = shopify_request('POST', shopify_api_url('custom_collections.json'),
        json={'custom_collection': {'title': ct, 'published': True}})
    if r.status_code == 201:
        cid = r.json()['custom_collection']['id']
        publish_to_channels('Collection', cid)
        return cid
    return None


def add_product_to_collection(pid, cid):
    return shopify_request('POST', shopify_api_url('collects.json'),
        json={'collect': {'product_id': pid, 'collection_id': cid}}).status_code == 201


# ========== ä¸Šæ¶åˆ° Shopifyï¼ˆé©é…æ–°ç¶²ç«™çµæ§‹ï¼‰==========

def build_variants_from_product(product_data):
    """å¾çˆ¬å–çš„å•†å“è³‡æ–™å»ºæ§‹ Shopify variants"""
    colors = product_data.get('colors', []) or ['Default']
    sizes = product_data.get('sizes', []) or ['ONE SIZE']
    price_jpy = product_data.get('price_jpy', 0)
    weight = DEFAULT_WEIGHT

    variants = []
    options = []

    if len(colors) > 1 or (len(colors) == 1 and colors[0] != 'Default'):
        options.append({'name': 'Color', 'values': colors})
    if len(sizes) > 1 or (len(sizes) == 1 and sizes[0] != 'ONE SIZE'):
        options.append({'name': 'Size', 'values': sizes})

    if not options:
        options = [{'name': 'Title', 'values': ['Default Title']}]
        selling_price = calculate_selling_price(price_jpy, weight)
        variants.append({
            'variant_data': {
                'title': 'Default Title', 'price': f"{selling_price:.2f}",
                'sku': product_data.get('item_id', ''),
                'weight': weight, 'weight_unit': 'kg',
                'inventory_management': None, 'inventory_policy': 'continue',
                'requires_shipping': True, 'option1': 'Default Title'
            },
            'cost': price_jpy
        })
    else:
        # å»ºæ§‹æ‰€æœ‰é¡è‰² x å°ºå¯¸çµ„åˆ
        color_list = colors if any(c != 'Default' for c in colors) else [None]
        size_list = sizes if any(s != 'ONE SIZE' for s in sizes) else [None]

        for color in color_list:
            for size in size_list:
                selling_price = calculate_selling_price(price_jpy, weight)
                sku = product_data.get('item_id', '')
                if color:
                    sku += f"-{color[:3].upper()}"
                if size:
                    sku += f"-{size}"

                vd = {
                    'price': f"{selling_price:.2f}",
                    'sku': sku,
                    'weight': weight, 'weight_unit': 'kg',
                    'inventory_management': None, 'inventory_policy': 'continue',
                    'requires_shipping': True
                }
                opt_idx = 1
                if color:
                    vd[f'option{opt_idx}'] = color
                    opt_idx += 1
                if size:
                    vd[f'option{opt_idx}'] = size

                variants.append({'variant_data': vd, 'cost': price_jpy})

    return options, variants


def upload_to_shopify(product_data, collection_id=None):
    """ä¸Šæ¶å•†å“åˆ° Shopify"""
    title = product_data.get('title', '')
    description = product_data.get('description', '')
    handle = product_data.get('handle', '')
    item_id = product_data.get('item_id', handle)

    translated = translate_with_chatgpt(title, description)
    options, variants = build_variants_from_product(product_data)
    
    # Shopify é™åˆ¶ï¼šæœ€å¤š 100 å€‹ variants
    if len(variants) > 100:
        print(f"  [âš ï¸] {handle}: {len(variants)} variants è¶…é Shopify ä¸Šé™ 100ï¼Œæˆªæ–·")
        variants = variants[:100]

    # åœ–ç‰‡ä½¿ç”¨ URL
    images = []
    for idx, img_url in enumerate(product_data.get('images', [])[:10]):  # æœ€å¤š 10 å¼µ
        images.append({
            'src': img_url,
            'position': idx + 1,
            'filename': f"humanmade_{handle}_{idx+1}.jpg"
        })

    product_type = ''
    if any(kw in title.upper() for kw in ['JACKET', 'COAT']):
        product_type = 'Outerwear'
    elif any(kw in title.upper() for kw in ['T-SHIRT', 'TEE']):
        product_type = 'T-Shirts'
    elif any(kw in title.upper() for kw in ['HOODIE', 'SWEAT']):
        product_type = 'Sweatshirts'
    elif any(kw in title.upper() for kw in ['SHIRT']):
        product_type = 'Shirts'
    elif any(kw in title.upper() for kw in ['PANTS', 'TROUSER', 'SHORTS']):
        product_type = 'Pants'
    elif any(kw in title.upper() for kw in ['CAP', 'HAT', 'BEANIE']):
        product_type = 'Headwear'
    elif any(kw in title.upper() for kw in ['BAG', 'POUCH', 'TOTE']):
        product_type = 'Bags'

    shopify_product = {'product': {
        'title': translated['title'],
        'body_html': translated['description'],
        'vendor': 'Human Made',
        'product_type': product_type,
        'status': 'active',
        'published': True,
        'handle': f"humanmade-{handle}",
        'options': options,
        'variants': [v['variant_data'] for v in variants],
        'images': images,
        'tags': f"Human Made, æ—¥æœ¬, æ½®æµ, æœé£¾, {product_type}",
        'metafields_global_title_tag': translated['page_title'],
        'metafields_global_description_tag': translated['meta_description'],
        'metafields': [{'namespace': 'custom', 'key': 'link',
                        'value': f"{SOURCE_URL}/{product_data.get('category_path', 'all')}/{handle}.html", 'type': 'url'}]
    }}

    response = shopify_request('POST', shopify_api_url('products.json'), json=shopify_product)

    if response.status_code == 201:
        created = response.json()['product']
        product_id = created['id']
        created_variants = created.get('variants', [])

        # æ›´æ–° cost
        for idx, cv in enumerate(created_variants):
            if idx < len(variants):
                shopify_request('PUT', shopify_api_url(f"variants/{cv['id']}.json"),
                    json={'variant': {'id': cv['id'], 'cost': f"{variants[idx]['cost']:.2f}"}})

        if collection_id:
            add_product_to_collection(product_id, collection_id)
        publish_to_channels('Product', product_id)

        return {'success': True, 'product': created, 'translated': translated,
                'variants_count': len(created_variants)}
    else:
        return {'success': False, 'error': response.text}


# ========== Thread-safe ç‹€æ…‹æ›´æ–° ==========

def update_status(**kwargs):
    with status_lock:
        scrape_status.update(kwargs)


def increment_status(key, value=1):
    with status_lock:
        scrape_status[key] = scrape_status.get(key, 0) + value


# ========== ä¸»æµç¨‹ ==========

def run_scrape():
    global scrape_status
    try:
        with status_lock:
            scrape_status = {
                "running": True, "progress": 0, "total": 0, "current_product": "",
                "products": [], "errors": [], "uploaded": 0, "skipped": 0,
                "skipped_exists": 0, "filtered_by_price": 0, "out_of_stock": 0,
                "deleted": 0, "price_updated": 0
            }

        # === Step 1: Shopify Collection è¨­å®š ===
        update_status(current_product="è¨­å®š Shopify Collection...")
        collection_id = get_or_create_collection("Human Made")

        update_status(current_product="å–å¾— Collection å…§ç¾æœ‰å•†å“ï¼ˆGraphQLï¼‰...")
        collection_products_map = get_collection_products_with_details(collection_id)
        existing_handles = set(collection_products_map.keys())

        # === Step 2: Playwright çˆ¬å–æ‰€æœ‰å•†å“ ===
        update_status(current_product="å•Ÿå‹•ç€è¦½å™¨çˆ¬å– humanmade.jp...")

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        product_list = loop.run_until_complete(scrape_all_products_playwright())
        loop.close()

        # === å®‰å…¨æ©Ÿåˆ¶ï¼šä¾†æºå•†å“å¤ªå°‘å‰‡è·³éåˆªé™¤ ===
        source_too_few = len(product_list) < MIN_PRODUCTS_FOR_CLEANUP
        if source_too_few:
            print(f"[âš ï¸ å®‰å…¨æ©Ÿåˆ¶] ä¾†æºåƒ… {len(product_list)} å€‹å•†å“ï¼ˆé–€æª» {MIN_PRODUCTS_FOR_CLEANUP}ï¼‰ï¼Œå°‡è·³éåˆªé™¤")

        update_status(total=len(product_list))
        in_stock_handles = set()

        # === Step 3: ä¸Šæ¶/æ›´æ–°å•†å“ ===
        for idx, product in enumerate(product_list):
            update_status(progress=idx + 1)
            handle = product.get('handle', '')
            title = product.get('title', '')
            my_handle = f"humanmade-{handle}"
            price_jpy = product.get('price_jpy', 0)
            is_available = product.get('available', True)

            update_status(current_product=f"è™•ç†: {title[:30]}")

            if is_available:
                in_stock_handles.add(my_handle)

            # å·²å­˜åœ¨çš„å•†å“ â†’ è·³éï¼ˆæœªä¾†å¯åŠ åƒ¹æ ¼æ›´æ–°ï¼‰
            if my_handle in existing_handles:
                increment_status('skipped_exists')
                increment_status('skipped')
                continue

            # åƒ¹æ ¼éæ¿¾
            if price_jpy < MIN_PRICE:
                increment_status('filtered_by_price')
                increment_status('skipped')
                continue

            # ç„¡åº«å­˜ / å°šæœªé–‹è³£
            if not is_available:
                increment_status('out_of_stock')
                increment_status('skipped')
                continue

            # ä¸Šæ¶
            result = upload_to_shopify(product, collection_id)
            if result['success']:
                in_stock_handles.add(my_handle)
                existing_handles.add(my_handle)
                increment_status('uploaded')
                with status_lock:
                    scrape_status['products'].append({
                        'handle': handle,
                        'title': result.get('translated', {}).get('title', title),
                        'original_title': title,
                        'variants_count': result.get('variants_count', 0),
                        'status': 'success'
                    })
            else:
                error_msg = result.get('error', '')[:300]
                print(f"  [ä¸Šæ¶å¤±æ•—] {handle}: {error_msg}")
                with status_lock:
                    scrape_status['errors'].append({
                        'handle': handle, 'title': title, 'error': error_msg
                    })
                # å¦‚æœæ˜¯ 429 rate limitï¼Œå¤šç­‰ä¸€ä¸‹
                if '429' in str(error_msg) or 'throttle' in str(error_msg).lower():
                    print(f"  [RATE LIMIT] ç­‰å¾… 10 ç§’...")
                    time.sleep(10)
            time.sleep(1.0)  # æ¯å€‹å•†å“é–“éš” 1 ç§’ï¼ˆç¿»è­¯ + Shopify APIï¼‰

        # === Step 4: æ¸…ç†ï¼ˆå«å®‰å…¨æ©Ÿåˆ¶ï¼‰===
        if source_too_few:
            update_status(current_product="âš ï¸ ä¾†æºå•†å“éå°‘ï¼Œè·³éæ¸…ç†ä»¥é¿å…èª¤åˆª")
            print(f"[å®‰å…¨æ©Ÿåˆ¶] è·³éåˆªé™¤æ­¥é©Ÿ")
        else:
            update_status(current_product="æ¸…ç†ä¸‹æ¶/ç¼ºè²¨å•†å“...")
            for my_handle, product_info in collection_products_map.items():
                if my_handle not in in_stock_handles:
                    update_status(current_product=f"åˆªé™¤: {my_handle}")
                    print(f"[åˆªé™¤] {my_handle} / ID: {product_info['product_id']}")
                    if delete_product(product_info['product_id']):
                        increment_status('deleted')
                    time.sleep(0.5)

        update_status(current_product="å®Œæˆï¼")

    except Exception as e:
        import traceback
        traceback.print_exc()
        with status_lock:
            scrape_status['errors'].append({'error': str(e)})
    finally:
        with status_lock:
            scrape_status['running'] = False


# ========== Flask è·¯ç”± + å‰ç«¯ ==========

@app.route('/')
def index():
    token_loaded = load_shopify_token()
    token_status = '<span style="color: green;">âœ“ å·²è¼‰å…¥</span>' if token_loaded else '<span style="color: red;">âœ— æœªè¨­å®š</span>'
    return f'''<!DOCTYPE html>
<html lang="zh-TW">
<head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Human Made çˆ¬èŸ²å·¥å…· v3.0</title>
<style>*{{box-sizing:border-box}}body{{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,sans-serif;max-width:900px;margin:0 auto;padding:20px;background:#f5f5f5}}h1{{color:#333;border-bottom:2px solid #E74C3C;padding-bottom:10px}}.card{{background:white;border-radius:8px;padding:20px;margin-bottom:20px;box-shadow:0 2px 4px rgba(0,0,0,0.1)}}.btn{{background:#E74C3C;color:white;border:none;padding:12px 24px;border-radius:5px;cursor:pointer;font-size:16px;margin-right:10px}}.btn:hover{{background:#C0392B}}.btn:disabled{{background:#ccc;cursor:not-allowed}}.btn-secondary{{background:#3498db}}.btn-warning{{background:#e67e22}}.progress-bar{{width:100%;height:20px;background:#eee;border-radius:10px;overflow:hidden;margin:10px 0}}.progress-fill{{height:100%;background:linear-gradient(90deg,#E74C3C,#F39C12);transition:width 0.3s}}.status{{padding:10px;background:#f8f9fa;border-radius:5px;margin-top:10px}}.log{{max-height:400px;overflow-y:auto;font-family:monospace;font-size:13px;background:#1e1e1e;color:#d4d4d4;padding:15px;border-radius:5px}}.stats{{display:flex;gap:15px;margin-top:15px;flex-wrap:wrap}}.stat{{flex:1;min-width:80px;text-align:center;padding:15px;background:#f8f9fa;border-radius:5px}}.stat-number{{font-size:24px;font-weight:bold;color:#E74C3C}}.stat-label{{font-size:11px;color:#666;margin-top:5px}}.badge{{display:inline-block;padding:3px 8px;border-radius:3px;font-size:11px;font-weight:bold}}.badge-new{{background:#e74c3c;color:white}}.badge-info{{background:#3498db;color:white}}</style></head>
<body>
<h1>â¤ï¸ Human Made çˆ¬èŸ²å·¥å…· <small style="font-size:14px;color:#999;">v3.0</small> <span class="badge badge-new">Playwright</span></h1>
<div class="card">
<h3>âš¡ v3.0 é‡å¤§æ›´æ–°</h3>
<p style="color:#666;font-size:14px;">humanmade.jp å·²å¾ Shopify é·ç§»åˆ°è‡ªå»ºå¹³å°ï¼Œæœ¬ç‰ˆæœ¬ä½¿ç”¨ Playwright (Chromium) çœŸå¯¦ç€è¦½å™¨çˆ¬å–ã€‚</p>
<ul style="font-size:14px;color:#555;">
<li>âœ… Playwright headless browser ç¹é WAF å°é–</li>
<li>âœ… è‡ªå‹•æ””æˆª API è«‹æ±‚åµæ¸¬è³‡æ–™ç«¯é»</li>
<li>âœ… æ–° URL æ ¼å¼ï¼š<code>/all/HMxxxxxx.html</code></li>
<li>âœ… å®‰å…¨æ©Ÿåˆ¶ï¼šä¾†æºå•†å“ä¸è¶³æ™‚è·³éåˆªé™¤</li>
</ul>
</div>
<div class="card"><h3>Shopify é€£ç·šç‹€æ…‹</h3><p>Token: {token_status}</p>
<button class="btn btn-secondary" onclick="testShopify()">æ¸¬è©¦é€£ç·š</button>
<button class="btn btn-warning" onclick="testScrape()">ğŸ” æ¸¬è©¦çˆ¬å–ï¼ˆå‰ 3 å€‹ï¼‰</button>
<button class="btn" style="background:#27ae60" onclick="testUpload()">ğŸ§ª æ¸¬è©¦ä¸Šæ¶ï¼ˆå‰ 3 å€‹ï¼‰</button></div>
<div class="card"><h3>é–‹å§‹çˆ¬å–</h3>
<p>çˆ¬å– www.humanmade.jp æ‰€æœ‰å•†å“ä¸¦ä¸Šæ¶åˆ° Shopify</p>
<p style="color:#666;font-size:14px;">â€» æˆæœ¬åƒ¹ä½æ–¼ Â¥{MIN_PRICE} æˆ–ç„¡åº«å­˜çš„å•†å“å°‡è‡ªå‹•è·³é</p>
<p style="color:#e67e22;font-size:14px;font-weight:bold;">â€» å®‰å…¨æ©Ÿåˆ¶ï¼šä¾†æºå•†å“å°‘æ–¼ {MIN_PRODUCTS_FOR_CLEANUP} å€‹æ™‚è·³éåˆªé™¤</p>
<button class="btn" id="startBtn" onclick="startScrape()">ğŸš€ é–‹å§‹çˆ¬å–</button>
<div id="progressSection" style="display:none;">
<div class="progress-bar"><div class="progress-fill" id="progressFill" style="width:0%"></div></div>
<div class="status" id="statusText">æº–å‚™ä¸­...</div>
<div class="stats">
<div class="stat"><div class="stat-number" id="uploadedCount">0</div><div class="stat-label">å·²ä¸Šæ¶</div></div>
<div class="stat"><div class="stat-number" id="priceUpdatedCount" style="color:#3498db;">0</div><div class="stat-label">åƒ¹æ ¼æ›´æ–°</div></div>
<div class="stat"><div class="stat-number" id="skippedCount">0</div><div class="stat-label">å·²è·³é</div></div>
<div class="stat"><div class="stat-number" id="filteredCount">0</div><div class="stat-label">åƒ¹æ ¼éæ¿¾</div></div>
<div class="stat"><div class="stat-number" id="outOfStockCount">0</div><div class="stat-label">ç„¡åº«å­˜</div></div>
<div class="stat"><div class="stat-number" id="deletedCount" style="color:#e67e22;">0</div><div class="stat-label">å·²åˆªé™¤</div></div>
<div class="stat"><div class="stat-number" id="errorCount">0</div><div class="stat-label">éŒ¯èª¤</div></div>
</div></div></div>
<div class="card"><h3>åŸ·è¡Œæ—¥èªŒ</h3><div class="log" id="logArea">ç­‰å¾…é–‹å§‹...</div></div>
<script>
let pollInterval=null;
function log(msg,type=''){{const a=document.getElementById('logArea');const t=new Date().toLocaleTimeString();const c=type==='success'?'#4ec9b0':type==='error'?'#f14c4c':type==='warn'?'#dcdcaa':'#d4d4d4';a.innerHTML+='<div style="color:'+c+'">['+t+'] '+msg+'</div>';a.scrollTop=a.scrollHeight}}
function clearLog(){{document.getElementById('logArea').innerHTML=''}}
async function testShopify(){{log('æ¸¬è©¦ Shopify é€£ç·š...');try{{const r=await fetch('/api/test-shopify');const d=await r.json();if(d.success)log('âœ“ é€£ç·šæˆåŠŸï¼å•†åº—: '+d.shop.name,'success');else log('âœ— é€£ç·šå¤±æ•—: '+d.error,'error')}}catch(e){{log('âœ— '+e.message,'error')}}}}
async function testScrape(){{log('æ¸¬è©¦çˆ¬å– humanmade.jpï¼ˆå‰ 3 å€‹å•†å“ï¼‰...');log('â³ å•Ÿå‹•ç€è¦½å™¨ä¸­ï¼Œå¯èƒ½éœ€è¦ 30-60 ç§’...','warn');try{{const r=await fetch('/api/test-scrape',{{timeout:120000}});const d=await r.json();if(d.success){{log('âœ“ æ¸¬è©¦æˆåŠŸï¼æ‰¾åˆ° '+d.total_links+' å€‹å•†å“é€£çµ','success');(d.samples||[]).forEach(s=>log('  - '+s.item_id+': '+s.title+' Â¥'+s.price_jpy))}}else log('âœ— æ¸¬è©¦å¤±æ•—: '+(d.error||'æœªçŸ¥éŒ¯èª¤'),'error')}}catch(e){{log('âœ— '+e.message,'error')}}}}
async function testUpload(){{log('ğŸ§ª æ¸¬è©¦ä¸Šæ¶ï¼ˆçˆ¬å–å‰ 3 å€‹å•†å“ + ä¸Šæ¶åˆ° Shopifyï¼‰...');log('â³ å•Ÿå‹•ç€è¦½å™¨ + ç¿»è­¯ + ä¸Šæ¶ï¼Œç´„éœ€ 2-3 åˆ†é˜...','warn');try{{const r=await fetch('/api/test-upload',{{method:'POST'}});const d=await r.json();if(d.success){{log('========== æ¸¬è©¦ä¸Šæ¶çµæœ ==========','success');(d.results||[]).forEach(s=>{{if(s.status==='uploaded')log('âœ“ '+s.item_id+': '+s.title+' ('+s.variants_count+' variants)','success');else log('âœ— '+s.item_id+': '+s.status+' '+(s.error||''),'error')}})}}else log('âœ— æ¸¬è©¦å¤±æ•—: '+(d.error||'æœªçŸ¥éŒ¯èª¤'),'error')}}catch(e){{log('âœ— '+e.message,'error')}}}}
async function startScrape(){{clearLog();log('é–‹å§‹çˆ¬å–æµç¨‹ï¼ˆPlaywright v3.0ï¼‰...');log('â³ å•Ÿå‹• Chromium ç€è¦½å™¨...','warn');document.getElementById('startBtn').disabled=true;document.getElementById('progressSection').style.display='block';try{{const r=await fetch('/api/start',{{method:'POST'}});const d=await r.json();if(!d.success){{log('âœ— '+d.error,'error');document.getElementById('startBtn').disabled=false;return}}log('âœ“ çˆ¬å–ä»»å‹™å·²å•Ÿå‹•','success');pollInterval=setInterval(pollStatus,2000)}}catch(e){{log('âœ— '+e.message,'error');document.getElementById('startBtn').disabled=false}}}}
async function pollStatus(){{try{{const r=await fetch('/api/status');const d=await r.json();const p=d.total>0?(d.progress/d.total*100):0;document.getElementById('progressFill').style.width=p+'%';document.getElementById('statusText').textContent=d.current_product+' ('+d.progress+'/'+d.total+')';document.getElementById('uploadedCount').textContent=d.uploaded;document.getElementById('priceUpdatedCount').textContent=d.price_updated||0;document.getElementById('skippedCount').textContent=d.skipped;document.getElementById('filteredCount').textContent=d.filtered_by_price||0;document.getElementById('outOfStockCount').textContent=d.out_of_stock||0;document.getElementById('deletedCount').textContent=d.deleted||0;document.getElementById('errorCount').textContent=d.errors.length;if(!d.running&&d.progress>0){{clearInterval(pollInterval);document.getElementById('startBtn').disabled=false;log('========== çˆ¬å–å®Œæˆ ==========','success')}}}}catch(e){{}}}}
</script></body></html>'''


@app.route('/api/status')
def get_status():
    with status_lock:
        return jsonify(dict(scrape_status))


@app.route('/api/start', methods=['GET', 'POST'])
def api_start():
    if scrape_status['running']:
        return jsonify({'success': False, 'error': 'çˆ¬å–æ­£åœ¨é€²è¡Œä¸­'})
    if not load_shopify_token():
        return jsonify({'success': False, 'error': 'ç’°å¢ƒè®Šæ•¸æœªè¨­å®š'})
    threading.Thread(target=run_scrape, daemon=True).start()
    return jsonify({'success': True, 'message': 'Human Made v3.0 çˆ¬èŸ²å·²å•Ÿå‹•'})


@app.route('/api/test-shopify')
def test_shopify():
    if not load_shopify_token():
        return jsonify({'success': False, 'error': 'ç’°å¢ƒè®Šæ•¸æœªè¨­å®š'})
    r = shopify_request('GET', shopify_api_url('shop.json'))
    if r.status_code == 200:
        return jsonify({'success': True, 'shop': r.json()['shop']})
    return jsonify({'success': False, 'error': r.text}), 400


@app.route('/api/test-scrape')
def test_scrape():
    """æ¸¬è©¦çˆ¬å–ï¼ˆåªçˆ¬å‰ 3 å€‹å•†å“ï¼‰"""
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        async def test():
            from playwright.async_api import async_playwright
            async with async_playwright() as p:
                browser = await p.chromium.launch(
                    headless=True,
                    args=['--no-sandbox', '--disable-dev-shm-usage']
                )
                context = await browser.new_context(
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    locale='ja-JP'
                )
                page = await context.new_page()
                await page.goto(ALL_ITEMS_URL, wait_until='networkidle', timeout=60000)
                await page.wait_for_timeout(3000)

                # é—œé–‰ Cookie å½ˆçª—ï¼ˆå¤šç¨®æ–¹å¼å˜—è©¦ï¼‰
                print("[TEST] å˜—è©¦é—œé–‰ Cookie å½ˆçª—...")
                cookie_closed = False
                try:
                    btn = page.locator('text=åŒæ„ã™ã‚‹').first
                    if await btn.is_visible(timeout=3000):
                        await btn.click()
                        cookie_closed = True
                        print("[TEST] âœ“ é»æ“Šã€ŒåŒæ„ã™ã‚‹ã€é—œé–‰ Cookie")
                        await page.wait_for_timeout(1000)
                except:
                    pass
                if not cookie_closed:
                    print("[TEST] âš  Cookie å½ˆçª—æœªæ‰¾åˆ°æˆ–å·²é—œé–‰")

                # é—œé–‰ Global-e åœ‹éš›é‹é€å½ˆçª—
                print("[TEST] å˜—è©¦é—œé–‰ Global-e å½ˆçª—...")
                try:
                    await page.evaluate('''() => {
                        // ç›´æ¥ç§»é™¤ Global-e å½ˆçª—
                        const ge = document.getElementById('globalePopupWrapper');
                        if (ge) { ge.remove(); console.log('removed globalePopupWrapper'); }
                        // ä¹Ÿç§»é™¤å…¶ä»–å¯èƒ½çš„é®ç½©
                        document.querySelectorAll('[class*="globale"], [id*="globale"], [class*="overlay"]').forEach(el => {
                            if (el.style.position === 'fixed' || el.style.position === 'absolute' || 
                                getComputedStyle(el).position === 'fixed') {
                                el.remove();
                            }
                        });
                    }''')
                    print("[TEST] âœ“ å·²ç§»é™¤ Global-e å½ˆçª—")
                    await page.wait_for_timeout(1000)
                except Exception as e:
                    print(f"[TEST] Global-e è™•ç†: {e}")

                # æˆªåœ– debug
                await page.screenshot(path='/tmp/humanmade_test.png')
                print("[TEST] æˆªåœ–å·²å­˜è‡³ /tmp/humanmade_test.png")

                # æ¸¬è©¦åªç”¨ç¬¬ä¸€é ï¼Œä¸é» VIEW MORE

                # å–å¾—å•†å“é€£çµ
                links = await page.evaluate('''() => {
                    const items = new Map();
                    const excludePages = ['about', 'faq', 'shipping', 'payment', 'privacy', 'terms', 'inquiries', 'dealers', 'legal', 'counterfeit', 'maintenance'];
                    document.querySelectorAll('a[href]').forEach(a => {
                        const href = a.getAttribute('href') || '';
                        const match = href.match(/\\/([^\\/]+)\\/([A-Z][A-Z0-9]+)\\.html/);
                        if (match) {
                            const category = match[1];
                            const itemId = match[2];
                            if (!excludePages.some(ex => category.includes(ex))) {
                                items.set(itemId, category);
                            }
                        }
                    });
                    return Array.from(items.entries());
                }''')

                samples = []
                for item_id, category in links[:3]:
                    url = f"{SOURCE_URL}/{category}/{item_id}.html"
                    data = await scrape_product_page(page, url, item_id)
                    if data:
                        samples.append({
                            'item_id': item_id,
                            'title': data.get('title', 'N/A'),
                            'price_jpy': data.get('price_jpy', 0),
                            'colors': data.get('colors', []),
                            'sizes': data.get('sizes', []),
                            'images_count': len(data.get('images', [])),
                            'available': data.get('available', False)
                        })
                    await page.wait_for_timeout(1500)

                await browser.close()
                return {'total_links': len(links), 'samples': samples}

        result = loop.run_until_complete(test())
        loop.close()
        return jsonify({'success': True, **result})

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/test-upload', methods=['POST'])
def test_upload():
    """æ¸¬è©¦ä¸Šæ¶ï¼šçˆ¬å–å‰ 3 å€‹å•†å“ä¸¦ä¸Šæ¶åˆ° Shopify"""
    if not load_shopify_token():
        return jsonify({'success': False, 'error': 'ç’°å¢ƒè®Šæ•¸æœªè¨­å®š'})

    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        async def do_test_upload():
            from playwright.async_api import async_playwright
            async with async_playwright() as p:
                browser = await p.chromium.launch(
                    headless=True,
                    args=['--no-sandbox', '--disable-dev-shm-usage']
                )
                context = await browser.new_context(
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    locale='ja-JP'
                )
                page = await context.new_page()
                await page.goto(ALL_ITEMS_URL, wait_until='networkidle', timeout=60000)
                await page.wait_for_timeout(3000)

                # é—œé–‰å½ˆçª—
                try:
                    btn = page.locator('text=åŒæ„ã™ã‚‹').first
                    if await btn.is_visible(timeout=3000):
                        await btn.click()
                        await page.wait_for_timeout(1000)
                except:
                    pass
                try:
                    await page.evaluate('''() => {
                        const ge = document.getElementById('globalePopupWrapper');
                        if (ge) ge.remove();
                    }''')
                except:
                    pass

                # å–å¾—å•†å“é€£çµï¼ˆä¸ç”¨ VIEW MOREï¼Œé¦–é å°±å¤ äº†ï¼‰
                links = await page.evaluate('''() => {
                    const items = new Map();
                    const excludePages = ['about', 'faq', 'shipping', 'payment', 'privacy', 'terms', 'inquiries', 'dealers', 'legal', 'counterfeit', 'maintenance'];
                    document.querySelectorAll('a[href]').forEach(a => {
                        const href = a.getAttribute('href') || '';
                        const match = href.match(/\\/([^\\/]+)\\/([A-Z][A-Z0-9]+)\\.html/);
                        if (match) {
                            const category = match[1];
                            const itemId = match[2];
                            if (!excludePages.some(ex => category.includes(ex))) {
                                items.set(itemId, category);
                            }
                        }
                    });
                    return Array.from(items.entries());
                }''')

                # å–å‰ 3 å€‹çˆ¬å– + ä¸Šæ¶
                collection_id = get_or_create_collection("Human Made")
                results = []

                for item_id, category in links[:3]:
                    url = f"{SOURCE_URL}/{category}/{item_id}.html"
                    print(f"[TEST UPLOAD] çˆ¬å–: {item_id}...")
                    data = await scrape_product_page(page, url, item_id)

                    if not data:
                        results.append({'item_id': item_id, 'status': 'scrape_failed'})
                        continue

                    data['category_path'] = category  # ä¿å­˜é¡åˆ¥è·¯å¾‘

                    print(f"[TEST UPLOAD] ä¸Šæ¶: {data.get('title', item_id)} Â¥{data.get('price_jpy', 0)}")
                    upload_result = upload_to_shopify(data, collection_id)

                    if upload_result['success']:
                        results.append({
                            'item_id': item_id,
                            'title': upload_result.get('translated', {}).get('title', ''),
                            'original_title': data.get('title', ''),
                            'price_jpy': data.get('price_jpy', 0),
                            'variants_count': upload_result.get('variants_count', 0),
                            'status': 'uploaded'
                        })
                        print(f"[TEST UPLOAD] âœ“ ä¸Šæ¶æˆåŠŸ: {item_id}")
                    else:
                        results.append({
                            'item_id': item_id,
                            'title': data.get('title', ''),
                            'status': 'upload_failed',
                            'error': upload_result.get('error', '')[:200]
                        })
                        print(f"[TEST UPLOAD] âœ— ä¸Šæ¶å¤±æ•—: {upload_result.get('error', '')[:100]}")

                    await page.wait_for_timeout(1500)

                await browser.close()
                return results

        results = loop.run_until_complete(do_test_upload())
        loop.close()
        return jsonify({'success': True, 'results': results})

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)})


if __name__ == '__main__':
    print("Human Made çˆ¬èŸ²å·¥å…· v3.0 (Playwright)")
    load_shopify_token()
    app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 8080)), debug=False)
