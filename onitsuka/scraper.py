"""
Onitsuka Tiger Japan çˆ¬èŸ² (GraphQL + Shopify)
===============================================
- ä½¿ç”¨ Magento GraphQL API çˆ¬å– onitsukatiger.com/jp
- åˆ†é¡ï¼šç”·è£ã€å¥³è£ï¼ˆå…¨å“é¡ï¼šé‹ã€æœé£¾ã€åŒ…åŒ…ã€é…ä»¶ï¼‰
- å®šåƒ¹å…¬å¼: (å”®åƒ¹ + Â¥1,250) Ã· 0.7 = Shopifyå”®åƒ¹ (æ—¥å¹£)
- ChatGPT æ—¥æ–‡â†’ç¹é«”ä¸­æ–‡ç¿»è­¯
- è‡ªå‹•ä¸Šæ¶åˆ° Shopify + Collection ç®¡ç†
- é‡è¤‡å•†å“è‡ªå‹•è·³éï¼ˆSKU æ¯”å°ï¼‰
"""

import os
import re
import json
import math
import time
import logging
import requests
from datetime import datetime
from html import unescape

# ============================================================
# Logging
# ============================================================
logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(message)s")
logger = logging.getLogger("onitsuka")

# ============================================================
# ç’°å¢ƒè®Šæ•¸
# ============================================================
SHOPIFY_STORE = os.getenv("SHOPIFY_STORE", "")
SHOPIFY_ACCESS_TOKEN = os.getenv("SHOPIFY_ACCESS_TOKEN", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

# ============================================================
# Onitsuka Tiger GraphQL è¨­å®š
# ============================================================
GRAPHQL_URL = "https://www.onitsukatiger.com/jp/ja-jp/graphql"
BASE_URL = "https://www.onitsukatiger.com"
STORE_CODE = "default"

# åˆ†é¡è¨­å®šï¼šç”·è£ / å¥³è£
CATEGORIES = {
    "men": {
        "name": "ç”·è£ï¼ˆå…¨å“é¡ï¼‰",
        "collection": "Onitsuka Tiger ç”·è£",
        # MEN category in Magento â€” æœƒåœ¨ init æ™‚ç”¨ GraphQL å–å¾— uid
        "url_path": "store/men",
        "uid": None,
    },
    "women": {
        "name": "å¥³è£ï¼ˆå…¨å“é¡ï¼‰",
        "collection": "Onitsuka Tiger å¥³è£",
        "url_path": "store/women",
        "uid": None,
    },
}

PAGE_SIZE = 48
REQUEST_DELAY = 0.3


# ============================================================
# å®šåƒ¹å…¬å¼
# ============================================================
def calculate_price(original_price_jpy: int) -> int:
    """(å”®åƒ¹ + 1250) / 0.7 = Shopifyå”®åƒ¹ï¼Œç„¡æ¢ä»¶é€²ä½"""
    raw = (original_price_jpy + 1250) / 0.7
    return math.ceil(raw)


# ============================================================
# ç¿»è­¯ (ChatGPT API)
# ============================================================
def translate_ja_to_zhtw(text: str) -> str:
    """ç”¨ OpenAI ChatGPT å°‡æ—¥æ–‡ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡"""
    if not text or not text.strip():
        return text
    if not OPENAI_API_KEY:
        return text

    for attempt in range(3):
        try:
            resp = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {OPENAI_API_KEY}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": "gpt-4o-mini",
                    "messages": [
                        {
                            "role": "system",
                            "content": (
                                "ä½ æ˜¯ç¿»è­¯å°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹æ—¥æ–‡å•†å“æè¿°ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚\n"
                                "åš´æ ¼è¦å‰‡ï¼š\n"
                                "1. åªå›å‚³ç¿»è­¯çµæœï¼Œä¸è¦åŠ ä»»ä½•è§£é‡‹ã€‚\n"
                                "2. å“ç‰Œåå’Œå‹è™Ÿåä¿ç•™è‹±æ–‡åŸæ–‡ï¼ˆå¦‚ MEXICO 66, SERRANO, Onitsuka Tiger ç­‰ï¼‰ã€‚\n"
                                "3. ã€æœ€é‡è¦ã€‘è¼¸å‡ºä¸­çµ•å°ç¦æ­¢å‡ºç¾ä»»ä½•æ—¥æ–‡å­—å…ƒï¼š\n"
                                "   - ç¦æ­¢å¹³å‡åï¼ˆã‚-ã‚“ï¼‰\n"
                                "   - ç¦æ­¢ç‰‡å‡åï¼ˆã‚¢-ãƒ³ã€ã‚ªãƒ‹ãƒ„ã‚«ã‚¿ã‚¤ã‚¬ãƒ¼â†’Onitsuka Tigerã€ã‚¹ãƒˆãƒ©ã‚¤ãƒ—â†’æ¢ç´‹ï¼‰\n"
                                "   - æ‰€æœ‰ç‰‡å‡åå¤–ä¾†èªå¿…é ˆç¿»è­¯æˆä¸­æ–‡æˆ–é‚„åŸæˆè‹±æ–‡åŸæ–‡\n"
                                "   - ä¾‹ï¼šã‚ªãƒ‹ãƒ„ã‚«ã‚¿ã‚¤ã‚¬ãƒ¼ã‚¹ãƒˆãƒ©ã‚¤ãƒ—â†’Onitsuka Tiger æ¢ç´‹\n"
                                "   - ä¾‹ï¼šãƒ‡ãƒ©ãƒƒã‚¯ã‚¹â†’DELUXEã€ãƒ¬ã‚¶ãƒ¼â†’çš®é©ã€ã‚¹ãƒ‹ãƒ¼ã‚«ãƒ¼â†’é‹å‹•é‹\n"
                                "4. å¦‚æœåŸæ–‡å·²ç¶“æ˜¯è‹±æ–‡æˆ–ä¸­æ–‡ï¼Œç›´æ¥å›å‚³åŸæ–‡ã€‚\n"
                                "5. é©ç•¶æ›è¡Œè®“å…§å®¹å¥½é–±è®€ï¼š\n"
                                "   - æ¯å€‹å¥å­çµæŸå¾Œæ›è¡Œ\n"
                                "   - å•†å“ç‰¹é»ç”¨ ãƒ» é–‹é ­ï¼Œæ¯é …ç¨ç«‹ä¸€è¡Œ\n"
                                "   - ä¸è¦ä½¿ç”¨ HTML æ¨™ç±¤æ›è¡Œï¼Œç›´æ¥ç”¨æ›è¡Œç¬¦\n"
                                "6. HTML æ¨™ç±¤ä¿æŒä¸è®Šã€‚\n"
                                "7. ç¿»è­¯å®Œæˆå¾Œè‡ªæˆ‘æª¢æŸ¥ï¼Œå¦‚æœè¼¸å‡ºä¸­ä»æœ‰ä»»ä½•æ—¥æ–‡å­—å…ƒï¼Œå¿…é ˆå…¨éƒ¨æ›¿æ›ã€‚"
                            ),
                        },
                        {"role": "user", "content": text},
                    ],
                    "temperature": 0,
                    "max_tokens": 2000,
                },
                timeout=30,
            )
            if resp.status_code == 200:
                result = resp.json()["choices"][0]["message"]["content"].strip()
                # æœ€å¾Œé˜²ç·šï¼šç¨‹å¼åŒ–æ¸…é™¤æ®˜ç•™æ—¥æ–‡
                result = _strip_japanese_chars(result)
                return result
            elif resp.status_code == 429:
                wait = float(resp.headers.get("Retry-After", 3 * (attempt + 1)))
                logger.warning(f"  â³ OpenAI rate limitï¼Œç­‰å¾… {wait}s...")
                time.sleep(wait)
                continue
            else:
                logger.error(f"ç¿»è­¯ API éŒ¯èª¤: {resp.status_code}")
                return _strip_japanese_chars(text)
        except Exception as e:
            logger.error(f"ç¿»è­¯å¤±æ•— (attempt {attempt+1}): {e}")
            if attempt < 2:
                time.sleep(2)
            return _strip_japanese_chars(text)
    return _strip_japanese_chars(text)


def _strip_japanese_chars(text: str) -> str:
    """
    ç¨‹å¼åŒ–æ¸…é™¤æ–‡å­—ä¸­æ®˜ç•™çš„æ—¥æ–‡å­—å…ƒï¼ˆå¹³å‡åã€ç‰‡å‡åï¼‰
    é€™æ˜¯ç¿»è­¯å¾Œçš„æœ€å¾Œé˜²ç·š
    """
    if not text:
        return text
    # å¹³å‡å U+3040-U+309F, ç‰‡å‡å U+30A0-U+30FF
    # ä½†ä¿ç•™å¸¸ç”¨ä¸­æ—¥å…±ç”¨æ¨™é»ï¼ˆãƒ»ç­‰ï¼‰
    cleaned = re.sub(r'[\u3040-\u309F]', '', text)         # ç§»é™¤å¹³å‡å
    cleaned = re.sub(r'[\u30A1-\u30F6\u30F8-\u30FA]', '', cleaned)  # ç§»é™¤ç‰‡å‡åï¼ˆä¿ç•™ ãƒ» U+30FBï¼‰
    cleaned = re.sub(r'[\u30FC]', 'â€”', cleaned)             # é•·éŸ³ç¬¦ ãƒ¼ â†’ ç ´æŠ˜è™Ÿ
    # æ¸…ç†å¤šé¤˜ç©ºç™½
    cleaned = re.sub(r'  +', ' ', cleaned)
    cleaned = re.sub(r' ([ï¼Œã€‚ã€])', r'\1', cleaned)
    return cleaned.strip()


class DailyLimitReached(Exception):
    """Shopify æ¯æ—¥ variant å»ºç«‹ä¸Šé™å·²é”"""
    pass


def _api_request_with_retry(method, url, max_retries=3, **kwargs):
    """å¸¶ retry çš„ API è«‹æ±‚ï¼ˆè™•ç† 429 rate limitï¼‰"""
    for attempt in range(max_retries):
        resp = requests.request(method, url, **kwargs)
        if resp.status_code == 429:
            # æª¢æŸ¥æ˜¯å¦ç‚º daily limitï¼ˆä¸æ˜¯ä¸€èˆ¬ rate limitï¼Œretry ä¹Ÿæ²’ç”¨ï¼‰
            try:
                body = resp.json()
                errors = body.get("errors", {})
                error_text = json.dumps(errors)
                if "Daily variant creation limit" in error_text or "daily" in error_text.lower():
                    raise DailyLimitReached("Shopify æ¯æ—¥ variant å»ºç«‹ä¸Šé™å·²é”ï¼Œéœ€ç­‰å¾… 24 å°æ™‚é‡ç½®")
            except (ValueError, DailyLimitReached) as e:
                if isinstance(e, DailyLimitReached):
                    raise
            # ä¸€èˆ¬ rate limit â†’ retry
            retry_after = float(resp.headers.get("Retry-After", 2 * (attempt + 1)))
            logger.warning(f"  â³ Rate limit (429)ï¼Œç­‰å¾… {retry_after}s...")
            time.sleep(retry_after)
            continue
        return resp
    return resp


# ============================================================
# GraphQL çˆ¬èŸ²æ ¸å¿ƒ
# ============================================================
class OnitsukaScraper:
    """ä½¿ç”¨ Magento GraphQL API çˆ¬å– Onitsuka Tiger Japan"""

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Accept": "application/json",
            "Accept-Language": "ja-JP,ja;q=0.9",
            "Content-Type": "application/json",
            "Store": STORE_CODE,
            "Referer": f"{BASE_URL}/jp/ja-jp/",
            "Origin": BASE_URL,
        })

    def init(self):
        """åˆå§‹åŒ–ï¼šå– cookies + è§£æåˆ†é¡ UID + è§£æ gender å°æ‡‰è¡¨"""
        logger.info("åˆå§‹åŒ– session...")
        self._gender_map = {}  # Magento option_id â†’ æ€§åˆ¥æ–‡å­—
        try:
            self.session.get(f"{BASE_URL}/jp/ja-jp/", timeout=15)
            logger.info(f"  Cookies: {list(self.session.cookies.get_dict().keys())}")
        except Exception as e:
            logger.warning(f"  å– cookies å¤±æ•—: {e}")

        # å–å¾—åˆ†é¡ UID
        self._resolve_category_uids()
        # å–å¾— gender attribute çš„ option å°æ‡‰è¡¨
        self._resolve_gender_mapping()

    def _graphql(self, query, retries=3):
        """ç™¼é€ GraphQL è«‹æ±‚"""
        for attempt in range(retries):
            try:
                resp = self.session.post(
                    GRAPHQL_URL,
                    json={"query": query},
                    timeout=30,
                )
                if resp.status_code == 200:
                    data = resp.json()
                    if "errors" in data:
                        logger.warning(f"  GraphQL errors: {json.dumps(data['errors'], ensure_ascii=False)[:200]}")
                    return data.get("data")
                elif resp.status_code == 429:
                    time.sleep((attempt + 1) * 3)
                    continue
                elif resp.status_code == 503:
                    time.sleep((attempt + 1) * 2)
                    continue
                else:
                    logger.error(f"  GraphQL HTTP {resp.status_code}")
                    return None
            except requests.exceptions.Timeout:
                logger.warning(f"  GraphQL timeout, retry {attempt+1}/{retries}")
                time.sleep(2)
            except Exception as e:
                logger.error(f"  GraphQL error: {e}")
                return None
        return None

    def _resolve_category_uids(self):
        """ç”¨ GraphQL å–å¾—ç”·è£/å¥³è£åˆ†é¡çš„ UID"""
        logger.info("è§£æåˆ†é¡ UID...")
        query = """
        {
            categories(filters: {}, pageSize: 50, currentPage: 1) {
                items {
                    id uid name url_path product_count level
                    children {
                        id uid name url_path product_count level
                    }
                }
            }
        }
        """
        data = self._graphql(query)
        if not data:
            logger.error("ç„¡æ³•å–å¾—åˆ†é¡ï¼Œå°‡ä½¿ç”¨æœå°‹æ¨¡å¼")
            return

        all_cats = data.get("categories", {}).get("items", [])

        # å±•å¹³æœå°‹
        def find_cat(cats, target_path):
            for c in cats:
                if c.get("url_path") == target_path:
                    return c
                children = c.get("children", [])
                found = find_cat(children, target_path)
                if found:
                    return found
            return None

        for key, cat_config in CATEGORIES.items():
            found = find_cat(all_cats, cat_config["url_path"])
            if found:
                cat_config["uid"] = found["uid"]
                cat_config["magento_id"] = found["id"]
                logger.info(f"  âœ… {cat_config['name']}: uid={found['uid']}, id={found['id']}, products={found.get('product_count', '?')}")
            else:
                logger.warning(f"  âš ï¸ æ‰¾ä¸åˆ°åˆ†é¡: {cat_config['url_path']}")

    def _resolve_gender_mapping(self):
        """
        ç”¨ customAttributeMetadata æŸ¥è©¢ gender attribute çš„ option å°æ‡‰è¡¨
        Magento çš„ gender å›å‚³æ•¸å­— (å¦‚ 2787)ï¼Œéœ€è¦å°æ‡‰åˆ° MEN/WOMEN/UNISEX
        """
        logger.info("è§£æ gender å°æ‡‰è¡¨...")
        query = """
        {
            customAttributeMetadata(attributes: [
                { attribute_code: "gender", entity_type: "catalog_product" }
            ]) {
                items {
                    attribute_code
                    attribute_options {
                        value
                        label
                    }
                }
            }
        }
        """
        data = self._graphql(query)
        if not data:
            logger.warning("  âš ï¸ ç„¡æ³•æŸ¥è©¢ gender å°æ‡‰è¡¨ï¼Œä½¿ç”¨åˆ†é¡ fallback")
            return

        items = data.get("customAttributeMetadata", {}).get("items", [])
        for item in items:
            if item.get("attribute_code") == "gender":
                for opt in item.get("attribute_options", []):
                    val = str(opt.get("value", ""))
                    label = str(opt.get("label", "")).strip().upper()
                    self._gender_map[val] = label
                    logger.info(f"  gender {val} â†’ {label}")

        if self._gender_map:
            logger.info(f"  âœ… gender å°æ‡‰è¡¨: {len(self._gender_map)} å€‹é¸é …")
        else:
            logger.warning("  âš ï¸ gender attribute æ²’æœ‰ optionsï¼Œä½¿ç”¨åˆ†é¡ fallback")

    def scrape_category(self, category_key: str, max_pages: int = 0) -> list:
        """
        çˆ¬å–æŒ‡å®šåˆ†é¡çš„æ‰€æœ‰å•†å“
        max_pages=0 è¡¨ç¤ºå…¨éƒ¨
        """
        cat = CATEGORIES.get(category_key)
        if not cat:
            logger.error(f"ç„¡æ•ˆåˆ†é¡: {category_key}")
            return []

        uid = cat.get("uid")
        if not uid:
            logger.warning(f"åˆ†é¡ {cat['name']} æ²’æœ‰ UIDï¼Œå˜—è©¦ç”¨æœå°‹...")
            return []

        logger.info(f"=== é–‹å§‹çˆ¬å–: {cat['name']} (uid={uid}) ===")

        all_products = []
        page = 1

        while True:
            # å¸¶ gender æ¬„ä½æŸ¥è©¢ï¼ˆMagento è‡ªè¨‚å±¬æ€§å¯èƒ½å« gender ä¹Ÿå¯èƒ½ä¸å­˜åœ¨ï¼‰
            items_fields = """
                        id uid name sku url_key type_id
                        stock_status
                        %s
                        price_range {
                            minimum_price {
                                regular_price { value currency }
                                final_price { value currency }
                                discount { amount_off percent_off }
                            }
                        }
                        image { url label }
                        media_gallery { url label position }
                        short_description { html }
                        description { html }
                        ... on ConfigurableProduct {
                            configurable_options {
                                attribute_code label
                                values { value_index label }
                            }
                            variants {
                                product {
                                    id sku name stock_status
                                    image { url label }
                                }
                                attributes { code label value_index }
                            }
                        }
            """

            # ç¬¬ä¸€æ¬¡å˜—è©¦å¸¶ gender
            gender_field = "gender" if not hasattr(self, '_gender_field_broken') else ""
            query = """
            {
                products(
                    filter: { category_uid: { eq: "%s" } }
                    pageSize: %d
                    currentPage: %d
                    sort: { position: ASC }
                ) {
                    total_count
                    items {
                        %s
                    }
                    page_info { current_page page_size total_pages }
                }
            }
            """ % (uid, PAGE_SIZE, page, items_fields % gender_field)

            data = self._graphql(query)

            # å¦‚æœ gender æ¬„ä½å°è‡´ GraphQL å ±éŒ¯ï¼Œæ¨™è¨˜å¾Œä¸å¸¶ gender é‡è©¦
            if data is None and not hasattr(self, '_gender_field_broken'):
                logger.warning("  âš ï¸ GraphQL æŸ¥è©¢å¤±æ•—ï¼Œå˜—è©¦ä¸å¸¶ gender æ¬„ä½...")
                self._gender_field_broken = True
                query = """
                {
                    products(
                        filter: { category_uid: { eq: "%s" } }
                        pageSize: %d
                        currentPage: %d
                        sort: { position: ASC }
                    ) {
                        total_count
                        items {
                            %s
                        }
                        page_info { current_page page_size total_pages }
                    }
                }
                """ % (uid, PAGE_SIZE, page, items_fields % "")
                data = self._graphql(query)

            if not data or "products" not in data:
                logger.error(f"  ç¬¬ {page} é æŸ¥è©¢å¤±æ•—")
                break

            products = data["products"]
            items = products.get("items", [])
            total_count = products.get("total_count", 0)
            total_pages = products.get("page_info", {}).get("total_pages", 1)

            if page == 1:
                logger.info(f"  å…± {total_count} å€‹å•†å“, {total_pages} é ")

            # è½‰æ›ç‚ºçµ±ä¸€æ ¼å¼
            for item in items:
                product = self._normalize_product(item, category_key)
                if product:
                    # SKU å»é‡
                    if not any(p["sku"] == product["sku"] for p in all_products):
                        all_products.append(product)

            logger.info(f"  ç¬¬ {page}/{total_pages} é : +{len(items)} å•†å“ (ç´¯è¨ˆ {len(all_products)})")

            if page >= total_pages:
                break
            if max_pages > 0 and page >= max_pages:
                logger.info(f"  å·²é”æœ€å¤§é æ•¸é™åˆ¶ ({max_pages})")
                break

            page += 1
            time.sleep(REQUEST_DELAY)

        logger.info(f"  âœ… {cat['name']} å…±å–å¾— {len(all_products)} å€‹ä¸é‡è¤‡å•†å“")
        return all_products

    def _normalize_product(self, item: dict, category_key: str) -> dict | None:
        """å°‡ GraphQL å•†å“è³‡æ–™æ­£è¦åŒ–ç‚ºçµ±ä¸€æ ¼å¼"""
        sku = item.get("sku", "")
        if not sku:
            return None

        # åƒ¹æ ¼
        price_info = item.get("price_range", {}).get("minimum_price", {})
        regular_price = price_info.get("regular_price", {}).get("value", 0)
        final_price = price_info.get("final_price", {}).get("value", 0)
        discount = price_info.get("discount", {})

        # å–æ•´æ•¸åƒ¹æ ¼
        price_jpy = int(round(final_price)) if final_price else int(round(regular_price))
        if price_jpy <= 0:
            return None

        # URLï¼ˆåœ¨åœ–ç‰‡ä¹‹å‰è¨ˆç®—ï¼Œå› ç‚º fallback æŠ“åœ–éœ€è¦ï¼‰
        url_key = item.get("url_key", "")
        product_url = f"{BASE_URL}/jp/ja-jp/{url_key}.html" if url_key else ""

        # åœ–ç‰‡ç­–ç•¥ï¼š
        # GraphQL åˆ—è¡¨æŸ¥è©¢çš„ media_gallery åªå› 1 å¼µç¸®åœ–
        # å„ªå…ˆç”¨ Scene7 CDN çµ„åˆé«˜ç•«è³ªåœ–ï¼ˆå•†å“é å¯¦éš›ä½¿ç”¨çš„åœ–ç‰‡ä¾†æºï¼‰
        # Scene7 æ²’åœ–æ™‚ï¼ŒæŠ“å•†å“é  HTML æå–å¯¦éš›åœ–ç‰‡
        scene7_images = self._build_scene7_images(sku)
        if scene7_images:
            all_images = scene7_images
            main_image = all_images[0]
        else:
            # Scene7 æ²’åœ– â†’ æŠ“å•†å“é  HTML å–åœ–
            full_images = self._fetch_product_images(sku, product_url)
            if full_images:
                all_images = full_images
                main_image = all_images[0]
            else:
                # æœ€å¾Œ fallback: åˆ—è¡¨æŸ¥è©¢çš„ media_gallery
                gallery_images = []
                for media in sorted(item.get("media_gallery", []), key=lambda x: x.get("position", 99)):
                    url = media.get("url", "")
                    if url and url not in gallery_images:
                        gallery_images.append(url)
                if gallery_images:
                    all_images = gallery_images
                    main_image = all_images[0]
                    logger.warning(f"  âš ï¸ åƒ…åˆ—è¡¨ç¸®åœ–: {len(all_images)} å¼µ ({sku})")
                else:
                    main_image = item.get("image", {}).get("url", "")
                    all_images = [main_image] if main_image else []

        # å°ºå¯¸
        sizes = []
        configurable_options = item.get("configurable_options", [])
        variants = item.get("variants", [])

        for variant in variants:
            v_product = variant.get("product", {})
            v_attrs = variant.get("attributes", [])
            size_label = ""
            for attr in v_attrs:
                if attr.get("code", "").lower() in ("size", "shoe_size", "clothing_size"):
                    size_label = attr.get("label", "")
                    break
            # å¦‚æœæ²’æœ‰æ˜ç¢º size attributeï¼Œç”¨ç¬¬ä¸€å€‹ attribute
            if not size_label and v_attrs:
                size_label = v_attrs[0].get("label", "")

            if size_label:
                sizes.append({
                    "size": size_label,
                    "sku": v_product.get("sku", ""),
                    "available": v_product.get("stock_status") == "IN_STOCK",
                })

        # æè¿°
        desc_html = item.get("description", {}).get("html", "")
        short_desc_html = item.get("short_description", {}).get("html", "")

        # SKU è§£æ
        sku_parts = sku.split("_")
        item_code = sku_parts[0] if sku_parts else sku
        color_code = sku_parts[1] if len(sku_parts) > 1 else ""

        # æ€§åˆ¥åˆ¤æ–·
        # GraphQL å¯èƒ½å›å‚³ gender æ¬„ä½ï¼ˆæ•¸å€¼æˆ–æ–‡å­—ï¼‰
        # Magento å¸¸è¦‹: 1=MEN, 2=WOMEN, 3=UNISEXï¼Œæˆ–ç›´æ¥æ–‡å­—
        raw_gender = item.get("gender")
        gender = self._parse_gender(raw_gender, category_key)
        # åªå°å‰å¹¾å€‹å•†å“å° debugï¼ˆé¿å… log çˆ†é‡ï¼‰
        if not hasattr(self, '_gender_log_count'):
            self._gender_log_count = 0
        if self._gender_log_count < 5:
            logger.info(f"  ğŸ‘¤ {sku}: gender raw={raw_gender} â†’ {gender}")
            self._gender_log_count += 1

        # æ ¹æ“šæ€§åˆ¥æ±ºå®š Collectionsï¼ˆå¯å¤šå€‹ï¼‰
        collection_names = self._get_collections_by_gender(gender)

        return {
            "sku": sku,
            "item_code": item_code,
            "color_code": color_code,
            "title": item.get("name", ""),
            "price_jpy": price_jpy,
            "selling_price": calculate_price(price_jpy),
            "regular_price_jpy": int(round(regular_price)),
            "discount_percent": discount.get("percent_off", 0),
            "stock_status": item.get("stock_status", ""),
            "type": item.get("type_id", ""),
            "url": product_url,
            "image": main_image,
            "images": all_images,
            "sizes": sizes,
            "description_html": desc_html,
            "short_description_html": short_desc_html,
            "configurable_options": configurable_options,
            "category": category_key,
            "gender": gender,
            "collection_names": collection_names,
            "scraped_at": datetime.now().isoformat(),
        }

    @staticmethod
    def strip_html(html_text: str) -> str:
        """ç§»é™¤ HTML æ¨™ç±¤ï¼Œå–å¾—ç´”æ–‡å­—"""
        if not html_text:
            return ""
        text = re.sub(r'<[^>]+>', '', html_text)
        text = unescape(text)
        return text.strip()

    def _fetch_product_images(self, sku: str, product_url: str = "") -> list:
        """
        Scene7 æ²’åœ–çš„å•†å“ï¼Œç›´æ¥æŠ“å•†å“é  HTML å–å¾—å¯¦éš›åœ–ç‰‡ URL
        åœ–ç‰‡åœ¨ <div class="pdp-gallery-bigimg"> è£¡çš„ <img> tags
        URL æ ¼å¼: https://asics.scene7.com/is/image/asics/...?$otmag_zoom$&qlt=99,1
        æˆ– Magento CDN: https://static-ojp.onitsukatiger.com/media/catalog/product/...
        """
        if not product_url:
            # å¾ SKU çµ„åˆ URLï¼ˆéœ€è¦ url_keyï¼Œé€™è£¡ç”¨å‚™ç”¨æ–¹å¼ï¼‰
            return []

        try:
            resp = self.session.get(product_url, timeout=15)
            if resp.status_code != 200:
                logger.warning(f"  âš ï¸ å•†å“é  {resp.status_code}: {product_url}")
                return []

            html = resp.text
            images = []

            # æ–¹æ³•1: å¾ pdp-gallery-bigimg å€å¡Šæå– Scene7 åœ–ç‰‡
            # <img src="https://asics.scene7.com/is/image/asics/1182A187_101_SR_RT_GLB-1?$otmag_zoom$&qlt=99,1"
            gallery_match = re.findall(
                r'class="pdp-gallery-img"[^>]*>.*?<img[^>]+src="([^"]+)"',
                html, re.DOTALL
            )
            if gallery_match:
                for url in gallery_match:
                    if url and url not in images:
                        images.append(url)

            # æ–¹æ³•2: å¾ JSON-LD æˆ– script è£¡çš„ gallery data æå–
            if not images:
                # æœ‰äº› Magento æœƒåœ¨ script è£¡æ”¾ gallery JSON
                json_match = re.findall(
                    r'"full"\s*:\s*"(https?://[^"]+(?:scene7|onitsukatiger)[^"]*)"',
                    html
                )
                for url in json_match:
                    if url and url not in images:
                        images.append(url)

            # æ–¹æ³•3: æŠ“æ‰€æœ‰ scene7 æˆ– media/catalog åœ–ç‰‡ URL
            if not images:
                all_img_urls = re.findall(
                    r'(https://asics\.scene7\.com/is/image/asics/[^"\'&\s]+)',
                    html
                )
                seen = set()
                for url in all_img_urls:
                    # éæ¿¾æ‰ swatch å°åœ–å’Œé‡è¤‡
                    if 'swatch' in url.lower() or 'thumbnail' in url.lower():
                        continue
                    base_url = url.split('?')[0]  # å»æ‰ query params åšå»é‡
                    if base_url not in seen:
                        seen.add(base_url)
                        # åŠ ä¸Šé«˜ç•«è³ªåƒæ•¸
                        final_url = f"{base_url}?$otmag_zoom$&qlt=99,1"
                        images.append(final_url)

            if images:
                logger.info(f"  ğŸ“¸ å•†å“é : {len(images)} å¼µåœ–ç‰‡ ({sku})")
            else:
                logger.warning(f"  âš ï¸ å•†å“é ä¹Ÿæ²’æ‰¾åˆ°åœ–ç‰‡: {sku}")

            time.sleep(0.5)  # é¿å…å¤ªå¿«è§¸ç™¼åçˆ¬
            return images

        except Exception as e:
            logger.warning(f"  âš ï¸ æŠ“å•†å“é å¤±æ•— ({sku}): {e}")
            return []

    def _parse_gender(self, raw_gender, fallback_category: str = "") -> str:
        """
        è§£ææ€§åˆ¥æ¬„ä½
        Magento gender å›å‚³çš„æ˜¯ attribute option ID (å¦‚ 2787)
        éœ€è¦é€é _gender_map å°æ‡‰åˆ° MEN/WOMEN/UNISEX
        """
        if raw_gender is None:
            if fallback_category == "men":
                return "men"
            elif fallback_category == "women":
                return "women"
            return "unisex"

        raw_str = str(raw_gender).strip()

        # å…ˆæŸ¥å°æ‡‰è¡¨ï¼ˆæ•¸å­— option_id â†’ labelï¼‰
        if raw_str in self._gender_map:
            label = self._gender_map[raw_str]
        else:
            label = raw_str.upper()

        # è§£æ label
        if label in ("MEN", "MALE", "M", "ãƒ¡ãƒ³ã‚º"):
            return "men"
        elif label in ("WOMEN", "FEMALE", "W", "F", "ãƒ¬ãƒ‡ã‚£ãƒ¼ã‚¹", "ã‚¦ã‚£ãƒ¡ãƒ³ã‚º"):
            return "women"
        elif label in ("UNISEX", "U"):
            return "unisex"
        elif label in ("KIDS", "CHILDREN", "ã‚­ãƒƒã‚º"):
            return "kids"

        # fallback
        if fallback_category in ("men", "women"):
            return fallback_category
        return "unisex"

    @staticmethod
    def _get_collections_by_gender(gender: str) -> list:
        """æ ¹æ“šæ€§åˆ¥æ±ºå®šè¦åŠ å…¥å“ªäº› Collections"""
        if gender == "men":
            return ["Onitsuka Tiger ç”·è£"]
        elif gender == "women":
            return ["Onitsuka Tiger å¥³è£"]
        elif gender == "kids":
            return ["Onitsuka Tiger ç«¥è£"]
        else:
            # unisex â†’ ç”·å¥³éƒ½åŠ 
            return ["Onitsuka Tiger ç”·è£", "Onitsuka Tiger å¥³è£"]

    def _build_scene7_images(self, sku: str) -> list:
        """
        ç”¨ ASICS Scene7 CDN çµ„åˆå•†å“åœ–ç‰‡ URL
        
        ç­–ç•¥ï¼šåªæª¢æŸ¥ä¸»è¦çš„ 4 å€‹è§’åº¦ï¼ˆå°æ‡‰å•†å“é  HTML å¯¦éš›é¡¯ç¤ºçš„ï¼‰ï¼Œ
        ä¸æµªè²»æ™‚é–“æª¢æŸ¥æ‰€æœ‰ 10 å€‹å¾Œç¶´ã€‚
        """
        if not sku or "_" not in sku:
            return []

        scene7_base = f"https://asics.scene7.com/is/image/asics/{sku}"
        quality_param = "?$otmag_zoom$&qlt=99,1"

        # å•†å“é å¯¦éš›é¡¯ç¤ºçš„ 4 å€‹ä¸»è¦è§’åº¦ï¼ˆå¾ä½ è²¼çš„ HTML çœ‹åˆ°çš„ï¼‰
        primary_suffixes = [
            "SR_RT_GLB-1",   # å³å´ï¼ˆä¸»åœ–ï¼‰
            "SB_FR_GLB",     # æ­£é¢å³
            "SR_LT_GLB",     # å·¦å´
            "SB_FL_GLB",     # æ­£é¢å·¦
        ]
        # é¡å¤–è§’åº¦
        extra_suffixes = [
            "SB_TP_GLB",     # ä¿¯è¦–
            "SB_BT_GLB",     # åº•éƒ¨
            "SR_BK_GLB",     # å¾Œé¢
        ]

        images = []

        # å…ˆæª¢æŸ¥ä¸»åœ–æ˜¯å¦å­˜åœ¨ï¼ˆå¦‚æœä¸»åœ–éƒ½ä¸å­˜åœ¨ï¼Œé€™å€‹ SKU å°±ä¸åœ¨ Scene7 ä¸Šï¼‰
        main_url = f"{scene7_base}_{primary_suffixes[0]}{quality_param}"
        if not self._check_image_exists(main_url):
            # å˜—è©¦ä¸å¸¶ -1 çš„ä¸»åœ–
            alt_main = f"{scene7_base}_SR_RT_GLB{quality_param}"
            if not self._check_image_exists(alt_main):
                return []
            else:
                images.append(alt_main)
                # ç”¨ä¸å¸¶ -1 çš„æ¨¡å¼ç¹¼çºŒ
                for suffix in ["SB_FR_GLB", "SR_LT_GLB", "SB_FL_GLB"]:
                    url = f"{scene7_base}_{suffix}{quality_param}"
                    if self._check_image_exists(url):
                        images.append(url)
                logger.info(f"  ğŸ“¸ Scene7: {len(images)} å¼µåœ–ç‰‡ ({sku})")
                return images

        images.append(main_url)

        # ä¸»åœ–å­˜åœ¨ â†’ å…¶é¤˜ 3 å€‹å¤§æ¦‚ç‡ä¹Ÿå­˜åœ¨ï¼Œç›´æ¥åŠ å…¥ï¼ˆçœæ‰ HEAD è«‹æ±‚ï¼‰
        for suffix in primary_suffixes[1:]:
            images.append(f"{scene7_base}_{suffix}{quality_param}")

        # é¡å¤–è§’åº¦ç”¨æª¢æŸ¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
        for suffix in extra_suffixes:
            url = f"{scene7_base}_{suffix}{quality_param}"
            if self._check_image_exists(url):
                images.append(url)

        logger.info(f"  ğŸ“¸ Scene7: {len(images)} å¼µåœ–ç‰‡ ({sku})")
        return images

    def _check_image_exists(self, url: str) -> bool:
        """
        æª¢æŸ¥ Scene7 åœ–ç‰‡æ˜¯å¦å­˜åœ¨
        Scene7 å°ä¸å­˜åœ¨çš„ SKU æœƒå›å‚³ï¼š
        - 200 OK + ä¸€å€‹æ¥µå°çš„é è¨­ä½”ä½åœ– (é€šå¸¸ < 2KB)
        - æˆ– 200 OK + å« "default image" çš„å›æ‡‰
        çœŸæ­£çš„å•†å“åœ–ç‰‡é€šå¸¸ > 10KB
        """
        try:
            # ç”¨ Range header åªä¸‹è¼‰å‰ bytes ä¾†åˆ¤æ–· Content-Length
            resp = self.session.get(
                url,
                timeout=5,
                allow_redirects=True,
                stream=True,
                headers={**self.session.headers, "Range": "bytes=0-0"},
            )
            # æª¢æŸ¥ Content-Range æˆ– Content-Length
            if resp.status_code in (200, 206):
                # å¾ Content-Range å–å¾—å®Œæ•´å¤§å°: "bytes 0-0/123456"
                content_range = resp.headers.get("Content-Range", "")
                if "/" in content_range:
                    total_size = int(content_range.split("/")[-1])
                    resp.close()
                    return total_size > 10000  # > 10KB = çœŸåœ–
                # æ²’æœ‰ Content-Rangeï¼Œç”¨ Content-Length
                content_length = int(resp.headers.get("Content-Length", "0"))
                resp.close()
                return content_length > 10000
            resp.close()
            return False
        except Exception:
            return False


# ============================================================
# Shopify ä¸Šæ¶
# ============================================================
class ShopifyUploader:
    """å°‡å•†å“ä¸Šæ¶åˆ° Shopify"""

    def __init__(self):
        if not SHOPIFY_STORE or not SHOPIFY_ACCESS_TOKEN:
            logger.warning("æœªè¨­å®š Shopify ç’°å¢ƒè®Šæ•¸ï¼Œä¸Šæ¶åŠŸèƒ½ä¸å¯ç”¨")
        self.base_url = f"https://{SHOPIFY_STORE}.myshopify.com/admin/api/2026-01"
        self.headers = {
            "X-Shopify-Access-Token": SHOPIFY_ACCESS_TOKEN,
            "Content-Type": "application/json",
        }
        self._existing_skus = None
        self._collection_cache = {}
        self._publication_ids = None

    # --- éŠ·å”®ç®¡é“ ---
    def get_publication_ids(self) -> list:
        if self._publication_ids is not None:
            return self._publication_ids
        self._publication_ids = []
        graphql_url = f"https://{SHOPIFY_STORE}.myshopify.com/admin/api/2026-01/graphql.json"
        headers = {"X-Shopify-Access-Token": SHOPIFY_ACCESS_TOKEN, "Content-Type": "application/json"}
        query = '{ publications(first: 20) { edges { node { id name } } } }'
        try:
            resp = requests.post(graphql_url, headers=headers, json={"query": query}, timeout=15)
            if resp.status_code == 200:
                pubs = resp.json().get("data", {}).get("publications", {}).get("edges", [])
                seen = set()
                for pub in pubs:
                    name = pub["node"]["name"]
                    if name not in seen:
                        seen.add(name)
                        self._publication_ids.append(pub["node"]["id"])
                logger.info(f"æ‰¾åˆ° {len(self._publication_ids)} å€‹éŠ·å”®ç®¡é“: {', '.join(seen)}")
        except Exception as e:
            logger.error(f"å–å¾—éŠ·å”®ç®¡é“ç•°å¸¸: {e}")
        return self._publication_ids

    def publish_to_all_channels(self, resource_type: str, resource_id: int):
        pub_ids = self.get_publication_ids()
        if not pub_ids:
            return
        graphql_url = f"https://{SHOPIFY_STORE}.myshopify.com/admin/api/2026-01/graphql.json"
        headers = {"X-Shopify-Access-Token": SHOPIFY_ACCESS_TOKEN, "Content-Type": "application/json"}
        mutation = """
        mutation publishablePublish($id: ID!, $input: [PublicationInput!]!) {
          publishablePublish(id: $id, input: $input) {
            publishable { availablePublicationsCount { count } }
            userErrors { field message }
          }
        }
        """
        gid = f"gid://shopify/{resource_type}/{resource_id}"
        variables = {"id": gid, "input": [{"publicationId": pid} for pid in pub_ids]}
        try:
            resp = requests.post(graphql_url, headers=headers, json={"query": mutation, "variables": variables}, timeout=15)
            if resp.status_code == 200:
                errors = resp.json().get("data", {}).get("publishablePublish", {}).get("userErrors", [])
                if errors:
                    for err in errors:
                        logger.warning(f"  ç™¼å¸ƒè­¦å‘Š: {err.get('message')}")
                else:
                    logger.info(f"  âœ… {resource_type} {resource_id} å·²ç™¼å¸ƒåˆ° {len(pub_ids)} å€‹ç®¡é“")
        except Exception as e:
            logger.error(f"  ç™¼å¸ƒç•°å¸¸: {e}")

    # --- SKU é‡è¤‡æª¢æŸ¥ ---
    def get_existing_skus(self) -> set:
        if self._existing_skus is not None:
            return self._existing_skus
        skus = set()
        url = f"{self.base_url}/products.json?limit=250&fields=id,variants,tags"
        while url:
            try:
                resp = requests.get(url, headers=self.headers, timeout=30)
                if resp.status_code != 200:
                    break
                for product in resp.json().get("products", []):
                    for variant in product.get("variants", []):
                        sku = variant.get("sku", "")
                        if sku:
                            base_sku = sku.split("-")[0].upper()
                            skus.add(base_sku)
                            skus.add(sku.upper())
                link_header = resp.headers.get("Link", "")
                if 'rel="next"' in link_header:
                    match = re.search(r'<([^>]+)>;\s*rel="next"', link_header)
                    url = match.group(1) if match else None
                else:
                    url = None
            except Exception as e:
                logger.error(f"å–å¾— SKU å¤±æ•—: {e}")
                break
        logger.info(f"Shopify å·²æœ‰ {len(skus)} å€‹ SKU")
        self._existing_skus = skus
        return skus

    def is_duplicate(self, sku: str) -> bool:
        existing = self.get_existing_skus()
        # Onitsuka Tiger æ¯å€‹è‰²è™Ÿæ˜¯ç¨ç«‹å•†å“ï¼ŒåªæŸ¥å®Œæ•´ SKU
        return sku.upper() in existing

    def batch_rename_titles(self, old_prefix: str, new_prefix: str) -> dict:
        """
        æ‰¹æ¬¡ä¿®æ”¹å•†å“æ¨™é¡Œå‰ç¶´
        ä¾‹: "Onitsuka Tigerï½œ" â†’ "Onitsuka Tiger é¬¼å¡šè™ï½œ"
        """
        updated = 0
        skipped = 0
        errors = 0
        url = f"{self.base_url}/products.json?limit=250&fields=id,title"
        while url:
            try:
                resp = requests.get(url, headers=self.headers, timeout=30)
                if resp.status_code != 200:
                    logger.error(f"å–å¾—å•†å“å¤±æ•—: {resp.status_code}")
                    break
                products = resp.json().get("products", [])
                for p in products:
                    if old_prefix in p["title"] and new_prefix not in p["title"]:
                        new_title = p["title"].replace(old_prefix, new_prefix, 1)
                        put_resp = _api_request_with_retry(
                            "PUT",
                            f"{self.base_url}/products/{p['id']}.json",
                            headers=self.headers,
                            json={"product": {"id": p["id"], "title": new_title}},
                            timeout=15,
                        )
                        if put_resp.status_code == 200:
                            updated += 1
                            if updated % 20 == 0:
                                logger.info(f"  å·²æ›´æ–° {updated} å€‹å•†å“æ¨™é¡Œ...")
                        else:
                            errors += 1
                            logger.warning(f"  æ›´æ–°å¤±æ•— {p['id']}: {put_resp.status_code}")
                        time.sleep(0.3)
                    else:
                        skipped += 1
                # åˆ†é 
                link_header = resp.headers.get("Link", "")
                if 'rel="next"' in link_header:
                    match = re.search(r'<([^>]+)>;\s*rel="next"', link_header)
                    url = match.group(1) if match else None
                else:
                    url = None
            except Exception as e:
                logger.error(f"æ‰¹æ¬¡æ›´æ–°ç•°å¸¸: {e}")
                break
        logger.info(f"âœ… æ¨™é¡Œæ›´æ–°å®Œæˆ: {updated} å€‹æ›´æ–°, {skipped} å€‹è·³é, {errors} å€‹å¤±æ•—")
        return {"updated": updated, "skipped": skipped, "errors": errors}

    # --- Collection ---
    def get_or_create_collection(self, title: str) -> int | None:
        if title in self._collection_cache:
            return self._collection_cache[title]
        try:
            resp = requests.get(
                f"{self.base_url}/custom_collections.json?title={title}",
                headers=self.headers, timeout=30,
            )
            if resp.status_code == 200:
                for c in resp.json().get("custom_collections", []):
                    if c["title"] == title:
                        self._collection_cache[title] = c["id"]
                        self.publish_to_all_channels("Collection", c["id"])
                        return c["id"]
        except Exception:
            pass
        try:
            resp = requests.post(
                f"{self.base_url}/custom_collections.json",
                headers=self.headers,
                json={"custom_collection": {"title": title, "published": True}},
                timeout=30,
            )
            if resp.status_code == 201:
                cid = resp.json()["custom_collection"]["id"]
                self._collection_cache[title] = cid
                self.publish_to_all_channels("Collection", cid)
                return cid
        except Exception as e:
            logger.error(f"å»ºç«‹ Collection å¤±æ•—: {e}")
        return None

    def _add_to_collection(self, product_id: int, collection_id: int):
        try:
            requests.post(
                f"{self.base_url}/collects.json",
                headers=self.headers,
                json={"collect": {"product_id": product_id, "collection_id": collection_id}},
                timeout=30,
            )
        except Exception:
            pass

    # --- ä¸Šæ¶å•†å“ ---
    def upload_product(self, product: dict, translate: bool = True) -> dict:
        """ä¸Šæ¶å–®å€‹å•†å“åˆ° Shopify"""
        title = product["title"]
        sku = product["sku"]
        desc_html = product.get("description_html", "")
        short_desc = product.get("short_description_html", "")

        # ç¿»è­¯æè¿°
        if translate and OPENAI_API_KEY:
            if desc_html:
                desc_html = translate_ja_to_zhtw(desc_html)
            if short_desc:
                short_desc = translate_ja_to_zhtw(short_desc)

        # çµ„åˆ Shopify æ¨™é¡Œ
        full_title = f"Onitsuka Tiger é¬¼å¡šè™ï½œ{title}"

        # çµ„åˆæè¿° HTML
        body_parts = []
        if short_desc:
            body_parts.append(short_desc)
        if desc_html:
            body_parts.append(desc_html)

        # åˆä½µæè¿°æ–‡å­—ï¼Œçµ±ä¸€æ›è¡Œè™•ç†
        raw_desc = "\n".join(body_parts)
        # å…ˆå»æ‰å¤šé¤˜çš„ HTML æ¨™ç±¤ï¼ˆMagento ä¾†çš„å¯èƒ½åŒ… <p> ç­‰ï¼‰
        raw_desc = re.sub(r'</?p[^>]*>', '\n', raw_desc)
        raw_desc = re.sub(r'<br\s*/?>', '\n', raw_desc)
        # æ¸…ç†é€£çºŒç©ºè¡Œ
        raw_desc = re.sub(r'\n{3,}', '\n\n', raw_desc).strip()
        # æ¯è¡Œè½‰æˆ <p> æˆ– <br>ï¼Œè®“ Shopify æ­£ç¢ºæ›è¡Œé¡¯ç¤º
        lines = [line.strip() for line in raw_desc.split('\n') if line.strip()]
        body_html = '<br>\n'.join(lines)

        # å•†å“è³‡è¨Šè¡¨
        info_rows = []
        if product.get("color_code"):
            info_rows.append(f'<tr><td><strong>è‰²ç¢¼</strong></td><td>{product["color_code"]}</td></tr>')
        info_rows.append(f'<tr><td><strong>å‹è™Ÿ</strong></td><td>{sku}</td></tr>')
        info_rows.append(f'<tr><td><strong>å“ç•ª</strong></td><td>{product["item_code"]}</td></tr>')
        if info_rows:
            body_html += "\n<br><br>\n<table>" + "".join(info_rows) + "</table>"

        # åœ–ç‰‡
        images = []
        for img_url in product.get("images", [])[:20]:
            images.append({"src": img_url})
        if not images and product.get("image"):
            images.append({"src": product["image"]})

        # å»ºç«‹å°ºç¢¼ variants
        sizes = product.get("sizes", [])
        if sizes:
            variants = []
            size_stock = {}
            for s in sizes:
                size_name = s["size"]
                variant_sku = f"{sku}-{size_name.replace('.', '').replace(' ', '')}"
                variants.append({
                    "option1": size_name,
                    "price": str(product["selling_price"]),
                    "compare_at_price": None,
                    "sku": variant_sku,
                    "inventory_management": "shopify",
                    "requires_shipping": True,
                })
                size_stock[size_name] = 2 if s.get("available", True) else 0
            options = [{"name": "å°ºç¢¼", "values": [s["size"] for s in sizes]}]
        else:
            variants = [{
                "price": str(product["selling_price"]),
                "compare_at_price": None,
                "sku": sku,
                "inventory_management": "shopify",
                "requires_shipping": True,
            }]
            options = []
            size_stock = {"__default__": 2}

        # SEO
        seo = self._generate_seo(title, short_desc, sku)

        # Tags â€” ç”¨å¯¦éš›æ€§åˆ¥è€Œéçˆ¬å–åˆ†é¡
        gender = product.get("gender", "unisex")
        tags = ["Onitsuka Tiger", "é¬¼å¡šè™", sku, product.get("item_code", "")]
        if gender == "men":
            tags.append("ç”·è£")
        elif gender == "women":
            tags.append("å¥³è£")
        elif gender == "unisex":
            tags.extend(["ç”·è£", "å¥³è£", "UNISEX"])
        elif gender == "kids":
            tags.append("ç«¥è£")

        # Shopify payload
        payload = {
            "product": {
                "title": full_title,
                "body_html": body_html,
                "vendor": "Onitsuka Tiger",
                "product_type": "æœé£¾",
                "tags": tags,
                "variants": variants,
                "images": images,
                "status": "active",
                "published": True,
                "published_scope": "global",
                "metafields_global_title_tag": seo.get("title", full_title),
                "metafields_global_description_tag": seo.get("description", ""),
            }
        }
        if options:
            payload["product"]["options"] = options

        try:
            resp = _api_request_with_retry(
                "POST", f"{self.base_url}/products.json",
                headers=self.headers, json=payload, timeout=60,
            )
            if resp.status_code == 201:
                shopify_product = resp.json()["product"]
                product_id = shopify_product["id"]

                # è¨­å®šåº«å­˜
                self._set_inventory_levels(shopify_product, size_stock)
                # è¨­å®šåŸå§‹é€£çµ metafield
                self._set_product_metafield(product_id, product.get("url", ""))
                # åŠ å…¥æ‰€æœ‰ç›¸é—œ Collectionsï¼ˆæ ¹æ“šæ€§åˆ¥ï¼‰
                for col_name in product.get("collection_names", []):
                    col_id = self.get_or_create_collection(col_name)
                    if col_id:
                        self._add_to_collection(product_id, col_id)
                        logger.info(f"  ğŸ“‚ åŠ å…¥ Collection: {col_name}")
                # ç™¼å¸ƒ
                self.publish_to_all_channels("Product", product_id)

                gender_label = {"men": "ç”·", "women": "å¥³", "unisex": "ç”·+å¥³", "kids": "ç«¥"}
                logger.info(
                    f"âœ… ä¸Šæ¶æˆåŠŸ: {sku} - {title} â†’ Â¥{product['selling_price']} "
                    f"[{gender_label.get(gender, '?')}]"
                )
                self._existing_skus.add(sku.upper())
                return {"success": True, "product_id": product_id}
            else:
                logger.error(f"âŒ ä¸Šæ¶å¤±æ•—: {sku} - {resp.status_code} {resp.text[:200]}")
                return {"success": False, "error": resp.text[:200]}
        except DailyLimitReached:
            # å‘ä¸Šæ‹‹å‡ºï¼Œè®“ app.py è™•ç†ï¼ˆæš«åœç­‰å¾…ï¼‰
            raise
        except Exception as e:
            logger.error(f"âŒ ä¸Šæ¶ç•°å¸¸: {sku} - {e}")
            return {"success": False, "error": str(e)}

    def _set_product_metafield(self, product_id: int, url: str):
        if not url:
            return
        try:
            _api_request_with_retry(
                "POST", f"{self.base_url}/products/{product_id}/metafields.json",
                headers=self.headers,
                json={"metafield": {"namespace": "custom", "key": "link", "value": url, "type": "url"}},
                timeout=30,
            )
        except Exception:
            pass

    def _set_inventory_levels(self, shopify_product: dict, size_stock: dict):
        try:
            first_variant = shopify_product.get("variants", [{}])[0]
            first_inv_id = first_variant.get("inventory_item_id")
            if not first_inv_id:
                return
            inv_resp = _api_request_with_retry(
                "GET", f"{self.base_url}/inventory_levels.json?inventory_item_ids={first_inv_id}",
                headers=self.headers, timeout=30,
            )
            inv_levels = inv_resp.json().get("inventory_levels", [])
            if inv_levels:
                location_id = inv_levels[0]["location_id"]
            else:
                loc_resp = _api_request_with_retry(
                    "GET", f"{self.base_url}/locations.json",
                    headers=self.headers, timeout=30,
                )
                locations = loc_resp.json().get("locations", [])
                if not locations:
                    return
                location_id = locations[0]["id"]

            has_default = "__default__" in size_stock
            in_stock = out_stock = 0
            for variant in shopify_product.get("variants", []):
                size_name = variant.get("option1", "")
                qty = size_stock["__default__"] if has_default else size_stock.get(size_name, 0)
                inv_item_id = variant.get("inventory_item_id")
                if not inv_item_id:
                    continue
                resp = _api_request_with_retry(
                    "POST", f"{self.base_url}/inventory_levels/set.json",
                    headers=self.headers,
                    json={"location_id": location_id, "inventory_item_id": inv_item_id, "available": qty},
                    timeout=30,
                )
                if resp.status_code == 200:
                    if qty > 0:
                        in_stock += 1
                    else:
                        out_stock += 1
            logger.info(f"  ğŸ“¦ åº«å­˜: {in_stock} æœ‰è²¨, {out_stock} ç¼ºè²¨")
        except Exception as e:
            logger.warning(f"  âš ï¸ åº«å­˜è¨­å®šå¤±æ•—: {e}")

    @staticmethod
    def _generate_seo(title: str, desc: str, sku: str) -> dict:
        if not OPENAI_API_KEY:
            return {}
        prompt_text = f"""å•†å“åç¨±: {title}
å•†å“æè¿°: {desc[:200] if desc else ''}
å‹è™Ÿ: {sku}
å“ç‰Œ: Onitsuka Tiger (é¬¼å¡šè™)
å•†åº—: GOYOUTATI æ—¥æœ¬ä»£è³¼"""

        for attempt in range(3):
            try:
                resp = requests.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"},
                    json={
                        "model": "gpt-4o-mini",
                        "messages": [
                            {"role": "system", "content": (
                                "ä½ æ˜¯ SEO å°ˆå®¶ã€‚æ ¹æ“šå•†å“è³‡è¨Šç”Ÿæˆæœå°‹å¼•æ“å„ªåŒ–çš„é é¢æ¨™é¡Œå’Œ Meta æè¿°ã€‚"
                                "è¦å‰‡ï¼š"
                                "1. é é¢æ¨™é¡Œ(title)ï¼šæœ€å¤š 60 å­—å…ƒï¼ŒåŒ…å«å“ç‰Œåã€å•†å“åã€é—œéµå­—ã€‚æ ¼å¼ç¯„ä¾‹ï¼šOnitsuka Tiger MEXICO 66 ç¶“å…¸é‹æ¬¾ï½œGOYOUTATI æ—¥æœ¬ä»£è³¼"
                                "2. Meta æè¿°(description)ï¼šæœ€å¤š 155 å­—å…ƒï¼Œè‡ªç„¶æµæš¢çš„ç¹é«”ä¸­æ–‡ã€‚"
                                "3. ä¸è¦å‡ºç¾æ—¥æ–‡ã€‚4. åªå›å‚³ JSONï¼š{\"title\": \"...\", \"description\": \"...\"}"
                            )},
                            {"role": "user", "content": prompt_text},
                        ],
                        "temperature": 0, "max_tokens": 300,
                    },
                    timeout=30,
                )
                if resp.status_code == 200:
                    content = resp.json()["choices"][0]["message"]["content"].strip()
                    content = content.replace("```json", "").replace("```", "").strip()
                    return json.loads(content)
                elif resp.status_code == 429:
                    time.sleep(3 * (attempt + 1))
                    continue
            except Exception:
                pass
        return {}
