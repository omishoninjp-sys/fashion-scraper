"""
WORKMAN å•†å“çˆ¬èŸ² + Shopify ä¸Šæ¶å·¥å…·
ä¾†æºï¼šworkman.jp
åŠŸèƒ½ï¼š
1. çˆ¬å– workman.jp ç”·è£(c52)å’Œå¥³è£(c53)æ‰€æœ‰å•†å“
2. è§£æé¡è‰²å’Œå°ºå¯¸ï¼Œå»ºç«‹ Variants
3. åœ–ç‰‡ä¸‹è¼‰ä¸¦ä¸Šå‚³
4. åƒ¹æ ¼åŒæ­¥ï¼šå·²å­˜åœ¨å•†å“è‹¥åƒ¹æ ¼è®Šå‹•å‰‡è‡ªå‹•æ›´æ–°
5. ç„¡åº«å­˜å•†å“è¨­ç‚ºè‰ç¨¿
6. Collection å»ºç«‹å¾Œç™¼å¸ƒåˆ°æ‰€æœ‰ channels
"""

from flask import Flask, jsonify
import requests
from bs4 import BeautifulSoup
import re
import json
import os
import time
import threading
import base64

app = Flask(__name__)

# ========== è¨­å®š ==========
SHOPIFY_SHOP = ""
SHOPIFY_ACCESS_TOKEN = ""

SOURCE_URL = "https://workman.jp"
CATEGORIES = {
    'work': {'url': '/shop/c/c51/', 'collection': 'WORKMAN ä½œæ¥­æœ', 'tags': 'WORKMAN, æ—¥æœ¬, æœé£¾, ä½œæ¥­æœ, å·¥ä½œæœ'},
    'mens': {'url': '/shop/c/c52/', 'collection': 'WORKMAN ç”·è£', 'tags': 'WORKMAN, æ—¥æœ¬, æœé£¾, ç”·è£'},
    'womens': {'url': '/shop/c/c53/', 'collection': 'WORKMAN å¥³è£', 'tags': 'WORKMAN, æ—¥æœ¬, æœé£¾, å¥³è£'},
    'kids': {'url': '/shop/c/c54/', 'collection': 'WORKMAN å…’ç«¥æœ', 'tags': 'WORKMAN, æ—¥æœ¬, æœé£¾, å…’ç«¥æœ, ç«¥è£'}
}

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
DEFAULT_WEIGHT = 0.5  # é è¨­é‡é‡ kg

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ja,en;q=0.9',
}

scrape_status = {
    "running": False,
    "progress": 0,
    "total": 0,
    "current_product": "",
    "products": [],
    "errors": [],
    "uploaded": 0,
    "skipped": 0,
    "skipped_exists": 0,
    "out_of_stock": 0,
    "set_to_draft": 0,
    "price_updated": 0
}


def load_shopify_token():
    global SHOPIFY_ACCESS_TOKEN, SHOPIFY_SHOP
    
    env_token = os.environ.get('SHOPIFY_ACCESS_TOKEN', '')
    env_shop = os.environ.get('SHOPIFY_SHOP', '')
    
    if env_token and env_shop:
        SHOPIFY_ACCESS_TOKEN = env_token
        SHOPIFY_SHOP = env_shop.replace('https://', '').replace('http://', '').replace('.myshopify.com', '').strip('/')
        print(f"[è¨­å®š] å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥ - å•†åº—: {SHOPIFY_SHOP}")
        return True
    
    token_file = "shopify_token.json"
    if os.path.exists(token_file):
        with open(token_file, 'r') as f:
            data = json.load(f)
            SHOPIFY_ACCESS_TOKEN = data.get('access_token', '')
            shop = data.get('shop', '')
            if shop:
                SHOPIFY_SHOP = shop.replace('https://', '').replace('http://', '').replace('.myshopify.com', '').strip('/')
            print(f"[è¨­å®š] å¾æª”æ¡ˆè¼‰å…¥ - å•†åº—: {SHOPIFY_SHOP}")
            return True
    return False


def get_shopify_headers():
    return {
        'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN,
        'Content-Type': 'application/json',
    }


def shopify_api_url(endpoint):
    return f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/{endpoint}"


def calculate_selling_price(cost, weight):
    """å”®åƒ¹ = [é€²è²¨åƒ¹ + (é‡é‡ * 1250)] / 0.7"""
    if not cost or cost <= 0:
        return 0
    weight = weight if weight and weight > 0 else DEFAULT_WEIGHT
    shipping_cost = weight * 1250
    price = (cost + shipping_cost) / 0.7
    return round(price)


def contains_japanese(text):
    """æª¢æ¸¬æ–‡å­—æ˜¯å¦åŒ…å«æ—¥æ–‡ï¼ˆå¹³å‡åã€ç‰‡å‡åï¼‰"""
    if not text:
        return False
    japanese_pattern = re.compile(r'[\u3040-\u309F\u30A0-\u30FF]')
    return bool(japanese_pattern.search(text))


def remove_japanese(text):
    """ç§»é™¤æ–‡å­—ä¸­çš„æ—¥æ–‡å­—å…ƒ"""
    if not text:
        return text
    cleaned = re.sub(r'[\u3040-\u309F\u30A0-\u30FF]+', '', text)
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    cleaned = re.sub(r'[ï¼ˆï¼‰\(\)]\s*[ï¼ˆï¼‰\(\)]', '', cleaned)
    cleaned = re.sub(r'\s*[/ï¼]\s*$', '', cleaned)
    cleaned = re.sub(r'^\s*[/ï¼]\s*', '', cleaned)
    return cleaned


def translate_with_chatgpt(title, description):
    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹æ—¥æœ¬æœé£¾å“ç‰Œå•†å“è³‡è¨Šç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼Œä¸¦å„ªåŒ– SEOã€‚

å•†å“åç¨±ï¼ˆæ—¥æ–‡ï¼‰ï¼š{title}
å•†å“èªªæ˜ï¼š{description[:1500] if description else ''}

è«‹å›å‚³ JSON æ ¼å¼ï¼ˆä¸è¦åŠ  markdown æ¨™è¨˜ï¼‰ï¼š
{{
    "title": "ç¿»è­¯å¾Œçš„å•†å“åç¨±ï¼ˆç¹é«”ä¸­æ–‡ï¼Œç°¡æ½”æœ‰åŠ›ï¼Œå‰é¢åŠ ä¸Š WORKMANï¼‰",
    "description": "ç¿»è­¯å¾Œçš„å•†å“èªªæ˜ï¼ˆç¹é«”ä¸­æ–‡ï¼Œä¿ç•™åŸæ„ä½†æ›´æµæš¢ï¼Œé©åˆé›»å•†å±•ç¤ºï¼Œæ¯å€‹é‡é»ç”¨ <br> æ›è¡Œï¼‰",
    "page_title": "SEO é é¢æ¨™é¡Œï¼ˆç¹é«”ä¸­æ–‡ï¼ŒåŒ…å«å“ç‰Œå’Œå•†å“ç‰¹è‰²ï¼Œ50-60å­—ä»¥å…§ï¼‰",
    "meta_description": "SEO æè¿°ï¼ˆç¹é«”ä¸­æ–‡ï¼Œå¸å¼•é»æ“Šï¼ŒåŒ…å«é—œéµå­—ï¼Œ100å­—ä»¥å…§ï¼‰"
}}

ã€æœ€é‡è¦è¦å‰‡ - çµ•å°ç¦æ­¢æ—¥æ–‡ã€‘ï¼š
- ç¦æ­¢å‡ºç¾ä»»ä½•å¹³å‡åï¼ˆã‚ã„ã†ãˆãŠç­‰ï¼‰
- ç¦æ­¢å‡ºç¾ä»»ä½•ç‰‡å‡åï¼ˆã‚¢ã‚¤ã‚¦ã‚¨ã‚ªç­‰ï¼‰
- å¦‚æœåŸæ–‡æœ‰æ—¥æ–‡ï¼Œå¿…é ˆç¿»è­¯æˆç¹é«”ä¸­æ–‡
- å¦‚æœç„¡æ³•ç¿»è­¯ï¼Œç›´æ¥çœç•¥è©²éƒ¨åˆ†

å…¶ä»–è¦å‰‡ï¼š
1. é€™æ˜¯æ—¥æœ¬å¹³åƒ¹æœé£¾å“ç‰Œ WORKMAN çš„å•†å“
2. å•†å“åç¨±é–‹é ­å¿…é ˆæ˜¯ã€ŒWORKMANã€
3. ç¿»è­¯è¦è‡ªç„¶æµæš¢ï¼Œä¸è¦ç”Ÿç¡¬
4. SEO å…§å®¹è¦åŒ…å«ï¼šWORKMANã€æ—¥æœ¬ã€å¹³åƒ¹ã€æ©Ÿèƒ½æœé£¾ç­‰é—œéµå­—
5. description ä¸­æ¯å€‹é‡é»ç”¨ <br> æ›è¡Œï¼Œæ–¹ä¾¿é–±è®€
6. åªå›å‚³ JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—"""

    try:
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚ã€æœ€é«˜å„ªå…ˆè¦å‰‡ã€‘ä½ çš„è¼¸å‡ºçµ•å°ç¦æ­¢å‡ºç¾ä»»ä½•æ—¥æ–‡å­—å…ƒï¼ˆå¹³å‡åã€ç‰‡å‡åï¼‰ã€‚æ‰€æœ‰å…§å®¹å¿…é ˆæ˜¯ç¹é«”ä¸­æ–‡æˆ–è‹±æ–‡ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0,
                "max_tokens": 1000
            },
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            content = content.strip()
            if content.startswith('```'):
                content = content.split('\n', 1)[1]
            if content.endswith('```'):
                content = content.rsplit('```', 1)[0]
            content = content.strip()
            
            translated = json.loads(content)
            
            trans_title = translated.get('title', title)
            trans_desc = translated.get('description', description)
            trans_page_title = translated.get('page_title', '')
            trans_meta_desc = translated.get('meta_description', '')
            
            # æª¢æŸ¥ä¸¦ç§»é™¤æ—¥æ–‡
            if contains_japanese(trans_title):
                print(f"[è­¦å‘Š] æ¨™é¡ŒåŒ…å«æ—¥æ–‡ï¼Œæ­£åœ¨ç§»é™¤")
                trans_title = remove_japanese(trans_title)
            if contains_japanese(trans_desc):
                print(f"[è­¦å‘Š] æè¿°åŒ…å«æ—¥æ–‡ï¼Œæ­£åœ¨ç§»é™¤")
                trans_desc = remove_japanese(trans_desc)
            if contains_japanese(trans_page_title):
                trans_page_title = remove_japanese(trans_page_title)
            if contains_japanese(trans_meta_desc):
                trans_meta_desc = remove_japanese(trans_meta_desc)
            
            if not trans_title.startswith('WORKMAN'):
                trans_title = f"WORKMAN {trans_title}"
            
            return {
                'success': True,
                'title': trans_title,
                'description': trans_desc,
                'page_title': trans_page_title,
                'meta_description': trans_meta_desc
            }
        else:
            print(f"[OpenAI éŒ¯èª¤] {response.status_code}: {response.text}")
            return {
                'success': False,
                'title': f"WORKMAN {title}",
                'description': description,
                'page_title': '',
                'meta_description': ''
            }
            
    except Exception as e:
        print(f"[ç¿»è­¯éŒ¯èª¤] {e}")
        return {
            'success': False,
            'title': f"WORKMAN {title}",
            'description': description,
            'page_title': '',
            'meta_description': ''
        }


def download_image_to_base64(img_url, max_retries=3):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
        'Referer': SOURCE_URL + '/',
    }
    
    for attempt in range(max_retries):
        try:
            response = requests.get(img_url, headers=headers, timeout=30)
            if response.status_code == 200:
                content_type = response.headers.get('Content-Type', 'image/jpeg')
                if 'jpeg' in content_type or 'jpg' in content_type:
                    img_format = 'image/jpeg'
                elif 'png' in content_type:
                    img_format = 'image/png'
                elif 'webp' in content_type:
                    img_format = 'image/webp'
                else:
                    img_format = 'image/jpeg'
                
                img_base64 = base64.b64encode(response.content).decode('utf-8')
                return {'success': True, 'base64': img_base64, 'content_type': img_format}
            else:
                print(f"[åœ–ç‰‡ä¸‹è¼‰] ç¬¬ {attempt+1} æ¬¡å˜—è©¦å¤±æ•—: HTTP {response.status_code}")
        except Exception as e:
            print(f"[åœ–ç‰‡ä¸‹è¼‰] ç¬¬ {attempt+1} æ¬¡å˜—è©¦ç•°å¸¸: {e}")
        time.sleep(1)
    
    return {'success': False}


def get_collection_products_with_details(collection_id):
    """å–å¾— Collection å…§çš„å•†å“ï¼ˆåŒ…å« variants è©³ç´°è³‡è¨Šï¼‰"""
    products_map = {}
    if not collection_id:
        return products_map
    
    url = shopify_api_url(f"collections/{collection_id}/products.json?limit=250")
    
    while url:
        response = requests.get(url, headers=get_shopify_headers())
        if response.status_code != 200:
            break
        
        data = response.json()
        for product in data.get('products', []):
            product_id = product.get('id')
            handle = product.get('handle')
            if handle and product_id:
                variants_info = []
                for v in product.get('variants', []):
                    variant_id = v.get('id')
                    cost = None
                    
                    variant_response = requests.get(
                        shopify_api_url(f"variants/{variant_id}.json"),
                        headers=get_shopify_headers()
                    )
                    if variant_response.status_code == 200:
                        variant_data = variant_response.json().get('variant', {})
                        cost = variant_data.get('cost')
                    time.sleep(0.1)
                    
                    variants_info.append({
                        'variant_id': variant_id,
                        'price': v.get('price'),
                        'cost': cost,
                        'sku': v.get('sku'),
                        'option1': v.get('option1'),
                        'option2': v.get('option2'),
                        'option3': v.get('option3'),
                    })
                products_map[handle] = {
                    'product_id': product_id,
                    'variants': variants_info
                }
        
        link_header = response.headers.get('Link', '')
        if 'rel="next"' in link_header:
            match = re.search(r'<([^>]+)>; rel="next"', link_header)
            url = match.group(1) if match else None
        else:
            url = None
    
    print(f"[INFO] Collection å…§æœ‰ {len(products_map)} å€‹å•†å“")
    return products_map


def set_product_to_draft(product_id):
    url = shopify_api_url(f"products/{product_id}.json")
    response = requests.put(url, headers=get_shopify_headers(), json={
        "product": {"id": product_id, "status": "draft"}
    })
    if response.status_code == 200:
        print(f"[è¨­ç‚ºè‰ç¨¿] Product ID: {product_id}")
        return True
    return False


def publish_collection_to_all_channels(collection_id):
    """ç™¼å¸ƒ Collection åˆ°æ‰€æœ‰éŠ·å”®æ¸ é“"""
    print(f"[ç™¼å¸ƒ] æ­£åœ¨ç™¼å¸ƒ Collection {collection_id} åˆ°æ‰€æœ‰æ¸ é“...")
    
    graphql_url = f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/graphql.json"
    headers = {
        'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN,
        'Content-Type': 'application/json',
    }
    
    query = """
    {
      publications(first: 20) {
        edges {
          node {
            id
            name
          }
        }
      }
    }
    """
    
    response = requests.post(graphql_url, headers=headers, json={'query': query})
    
    if response.status_code != 200:
        return False
    
    result = response.json()
    publications = result.get('data', {}).get('publications', {}).get('edges', [])
    
    seen_names = set()
    unique_publications = []
    for pub in publications:
        name = pub['node']['name']
        if name not in seen_names:
            seen_names.add(name)
            unique_publications.append(pub['node'])
    
    publication_inputs = [{"publicationId": pub['id']} for pub in unique_publications]
    
    mutation = """
    mutation publishablePublish($id: ID!, $input: [PublicationInput!]!) {
      publishablePublish(id: $id, input: $input) {
        publishable {
          availablePublicationsCount { count }
        }
        userErrors { field message }
      }
    }
    """
    
    variables = {
        "id": f"gid://shopify/Collection/{collection_id}",
        "input": publication_inputs
    }
    
    pub_response = requests.post(graphql_url, headers=headers, json={
        'query': mutation,
        'variables': variables
    })
    
    return pub_response.status_code == 200


def get_or_create_collection(collection_title):
    response = requests.get(
        shopify_api_url(f'custom_collections.json?title={collection_title}'),
        headers=get_shopify_headers()
    )
    
    if response.status_code == 200:
        collections = response.json().get('custom_collections', [])
        for col in collections:
            if col['title'] == collection_title:
                print(f"[INFO] æ‰¾åˆ°ç¾æœ‰ Collection: {collection_title} (ID: {col['id']})")
                publish_collection_to_all_channels(col['id'])
                return col['id']
    
    response = requests.post(
        shopify_api_url('custom_collections.json'),
        headers=get_shopify_headers(),
        json={'custom_collection': {'title': collection_title, 'published': True}}
    )
    
    if response.status_code == 201:
        collection_id = response.json()['custom_collection']['id']
        print(f"[INFO] å»ºç«‹æ–° Collection: {collection_title} (ID: {collection_id})")
        publish_collection_to_all_channels(collection_id)
        return collection_id
    
    return None


def add_product_to_collection(product_id, collection_id):
    response = requests.post(
        shopify_api_url('collects.json'),
        headers=get_shopify_headers(),
        json={'collect': {'product_id': product_id, 'collection_id': collection_id}}
    )
    return response.status_code == 201


def publish_to_all_channels(product_id):
    graphql_url = f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/graphql.json"
    headers = {
        'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN,
        'Content-Type': 'application/json',
    }
    
    query = """
    {
      publications(first: 20) {
        edges {
          node {
            id
            name
          }
        }
      }
    }
    """
    
    response = requests.post(graphql_url, headers=headers, json={'query': query})
    if response.status_code != 200:
        return False
    
    result = response.json()
    publications = result.get('data', {}).get('publications', {}).get('edges', [])
    
    seen_names = set()
    unique_publications = []
    for pub in publications:
        name = pub['node']['name']
        if name not in seen_names:
            seen_names.add(name)
            unique_publications.append(pub['node'])
    
    publication_inputs = [{"publicationId": pub['id']} for pub in unique_publications]
    
    mutation = """
    mutation publishablePublish($id: ID!, $input: [PublicationInput!]!) {
      publishablePublish(id: $id, input: $input) {
        publishable {
          availablePublicationsCount { count }
        }
        userErrors { field message }
      }
    }
    """
    
    variables = {
        "id": f"gid://shopify/Product/{product_id}",
        "input": publication_inputs
    }
    
    pub_response = requests.post(graphql_url, headers=headers, json={
        'query': mutation,
        'variables': variables
    })
    
    return pub_response.status_code == 200


def get_total_pages(category_url):
    """å–å¾—åˆ†é¡çš„ç¸½é æ•¸"""
    url = SOURCE_URL + category_url
    try:
        response = requests.get(url, headers=HEADERS, timeout=30)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # æ‰¾ "æœ€å¾Œ" é€£çµ
            last_link = soup.find('a', string='æœ€å¾Œ')
            if last_link and last_link.get('href'):
                # /shop/c/c52_p14/ -> 14
                match = re.search(r'_p(\d+)', last_link['href'])
                if match:
                    return int(match.group(1))
            return 1
    except Exception as e:
        print(f"[ERROR] å–å¾—ç¸½é æ•¸å¤±æ•—: {e}")
    return 1


def fetch_product_links_from_page(page_url):
    """å¾åˆ—è¡¨é å–å¾—å•†å“é€£çµ"""
    product_links = []
    try:
        response = requests.get(page_url, headers=HEADERS, timeout=30)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # æ‰¾æ‰€æœ‰å•†å“é€£çµ /shop/g/gXXXX/
            links = soup.find_all('a', href=re.compile(r'/shop/g/g\d+/'))
            seen = set()
            for link in links:
                href = link.get('href')
                if href and href not in seen:
                    seen.add(href)
                    product_links.append(SOURCE_URL + href)
    except Exception as e:
        print(f"[ERROR] å–å¾—å•†å“é€£çµå¤±æ•—: {e}")
    return product_links


def fetch_all_product_links(category_key):
    """å–å¾—åˆ†é¡ä¸‹æ‰€æœ‰å•†å“é€£çµ"""
    category = CATEGORIES[category_key]
    base_url = category['url']
    
    total_pages = get_total_pages(base_url)
    print(f"[INFO] {category['collection']} å…± {total_pages} é ")
    
    all_links = []
    
    for page in range(1, total_pages + 1):
        if page == 1:
            page_url = SOURCE_URL + base_url
        else:
            # /shop/c/c52/ -> /shop/c/c52_p2/
            page_url = SOURCE_URL + base_url.rstrip('/') + f'_p{page}/'
        
        print(f"[INFO] æ­£åœ¨è¼‰å…¥ç¬¬ {page}/{total_pages} é ...")
        links = fetch_product_links_from_page(page_url)
        all_links.extend(links)
        print(f"[INFO] ç¬¬ {page} é å–å¾— {len(links)} å€‹å•†å“")
        time.sleep(0.5)
    
    # å»é‡
    all_links = list(dict.fromkeys(all_links))
    print(f"[INFO] {category['collection']} å…± {len(all_links)} å€‹å•†å“")
    return all_links


def parse_product_page(url):
    """è§£æå•†å“é é¢"""
    try:
        response = requests.get(url, headers=HEADERS, timeout=30)
        if response.status_code != 200:
            return None
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # å•†å“åç¨±
        title_elem = soup.find('h1')
        title = title_elem.get_text(strip=True) if title_elem else ''
        
        # åƒ¹æ ¼
        price = 0
        price_elem = soup.find('h2', string=re.compile(r'[\d,]+å††'))
        if price_elem:
            price_text = price_elem.get_text(strip=True)
            price_match = re.search(r'([\d,]+)å††', price_text)
            if price_match:
                price = int(price_match.group(1).replace(',', ''))
        
        # å•†å“ç•ªè™Ÿ
        product_code = ''
        code_dt = soup.find('dt', string='å•†å“ç•ªå·')
        if code_dt:
            code_dd = code_dt.find_next_sibling('dd')
            if code_dd:
                product_code = code_dd.get_text(strip=True)
        
        # ç®¡ç†ç•ªè™Ÿï¼ˆç”¨æ–¼åœ–ç‰‡å’Œ handleï¼‰
        manage_code = ''
        manage_dt = soup.find('dt', string='ç®¡ç†ç•ªå·')
        if manage_dt:
            manage_dd = manage_dt.find_next_sibling('dd')
            if manage_dd:
                manage_code = manage_dd.get_text(strip=True)
        
        # å•†å“èªªæ˜
        description = ''
        desc_dt = soup.find('dt', string='å•†å“èª¬æ˜')
        if desc_dt:
            desc_dd = desc_dt.find_next_sibling('dd')
            if desc_dd:
                description = str(desc_dd)
        
        # é¡è‰²é¸é …ï¼ˆå¾åœ–ç‰‡ alt å–å¾—ï¼‰
        colors = []
        color_imgs = soup.find_all('img', src=re.compile(r'/img/goods/\d+/\d+_c\d+\.jpg'))
        for img in color_imgs:
            alt = img.get('alt', '')
            if alt and alt not in colors:
                colors.append(alt)
        
        # å¦‚æœæ²’æœ‰é¡è‰²åœ–ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰å–®ä¸€é¡è‰²
        if not colors:
            main_img = soup.find('img', src=re.compile(r'/img/goods/L/\d+_t1\.jpg'))
            if main_img:
                alt = main_img.get('alt', '')
                if alt:
                    colors.append(alt)
        
        if not colors:
            colors = ['æ¨™æº–']
        
        # å°ºå¯¸é¸é …ï¼ˆå¾è¦æ ¼è¡¨å–å¾—ï¼‰
        sizes = []
        size_dt = soup.find('dt', string='ã‚µã‚¤ã‚ºãƒ»ã‚¹ãƒšãƒƒã‚¯')
        if size_dt:
            size_dd = size_dt.find_next_sibling('dd')
            if size_dd:
                table = size_dd.find('table')
                if table:
                    # æ‰¾ç¬¬ä¸€è¡Œçš„ thï¼ˆå°ºå¯¸æ¨™é¡Œï¼‰
                    first_row = table.find('tr')
                    if first_row:
                        ths = first_row.find_all('th')
                        for th in ths[1:]:  # è·³éç¬¬ä¸€å€‹ï¼ˆé€šå¸¸æ˜¯ "ã‚µã‚¤ã‚º"ï¼‰
                            size = th.get_text(strip=True)
                            if size and size not in sizes:
                                sizes.append(size)
        
        if not sizes:
            sizes = ['FREE']
        
        # åœ–ç‰‡ - æ”¶é›†æ‰€æœ‰åœ–ç‰‡ä¸¦è½‰æ›ç‚ºå¤§åœ–
        images = []
        color_images = {}  # {é¡è‰²ç´¢å¼•: åœ–ç‰‡URL}
        
        # æ‰¾æ‰€æœ‰åœ–ç‰‡ (åŒ…å« _t1, _c1, _c2, _d1, _d2 ç­‰)
        all_imgs = soup.find_all('img', src=re.compile(r'/img/goods/'))
        seen_imgs = set()
        
        for img in all_imgs:
            img_src = img.get('src', '')
            if not img_src or img_src in seen_imgs:
                continue
            
            # è·³é icon åœ–ç‰‡
            if '/icon/' in img_src or 'logo' in img_src:
                continue
            
            # æå–æª”å
            filename_match = re.search(r'/(\d+_[a-z]\d+\.jpg)$', img_src)
            if not filename_match:
                filename_match = re.search(r'/(\d+_t\d+\.jpg)$', img_src)
            
            if filename_match:
                filename = filename_match.group(1)
                # è½‰æ›ç‚ºå¤§åœ– URL
                large_url = f"{SOURCE_URL}/img/goods/L/{filename}"
                
                if large_url not in seen_imgs:
                    seen_imgs.add(large_url)
                    
                    # ä¸»åœ– (_t1) æ”¾æœ€å‰é¢
                    if '_t1.' in filename:
                        images.insert(0, large_url)
                    # é¡è‰²åœ– (_c1, _c2...) è¨˜éŒ„å°æ‡‰é—œä¿‚
                    elif '_c' in filename:
                        images.append(large_url)
                        # æå–é¡è‰²ç´¢å¼•
                        c_match = re.search(r'_c(\d+)\.', filename)
                        if c_match:
                            color_idx = int(c_match.group(1)) - 1  # è½‰ç‚º 0-based
                            color_images[color_idx] = large_url
                    # è©³ç´°åœ– (_d1, _d2...)
                    elif '_d' in filename:
                        images.append(large_url)
        
        # å¦‚æœæ²’æ‰¾åˆ°åœ–ç‰‡ï¼Œå˜—è©¦ç›´æ¥ç”¨ç®¡ç†ç•ªè™Ÿçµ„åˆ
        if not images and manage_code:
            images.append(f"{SOURCE_URL}/img/goods/L/{manage_code}_t1.jpg")
            for i in range(1, len(colors) + 1):
                color_img = f"{SOURCE_URL}/img/goods/L/{manage_code}_c{i}.jpg"
                images.append(color_img)
                color_images[i-1] = color_img
        
        return {
            'url': url,
            'title': title,
            'price': price,
            'product_code': product_code,
            'manage_code': manage_code,
            'description': description,
            'colors': colors,
            'sizes': sizes,
            'images': images,
            'color_images': color_images  # é¡è‰²å°æ‡‰åœ–ç‰‡
        }
        
    except Exception as e:
        print(f"[ERROR] è§£æå•†å“é é¢å¤±æ•— {url}: {e}")
        return None


def update_product_prices(source_product, existing_product_info):
    """æ¯”å°ä¸¦æ›´æ–°å•†å“åƒ¹æ ¼ï¼ˆå®˜ç¶²åƒ¹æ ¼ vs Shopify æˆæœ¬åƒ¹ï¼‰"""
    existing_variants = existing_product_info['variants']
    source_price = source_product['price']
    
    updated = False
    
    for ev in existing_variants:
        shopify_cost = float(ev.get('cost', 0)) if ev.get('cost') else 0
        
        if abs(source_price - shopify_cost) >= 1:
            variant_id = ev['variant_id']
            
            new_selling_price = calculate_selling_price(source_price, DEFAULT_WEIGHT)
            
            print(f"[åƒ¹æ ¼æ›´æ–°] Variant {variant_id}: æˆæœ¬ Â¥{shopify_cost} -> Â¥{source_price}, å”®åƒ¹æ›´æ–°ç‚º Â¥{new_selling_price}")
            
            response = requests.put(
                shopify_api_url(f"variants/{variant_id}.json"),
                headers=get_shopify_headers(),
                json={
                    'variant': {
                        'id': variant_id,
                        'price': f"{new_selling_price:.2f}",
                        'cost': f"{source_price:.2f}"
                    }
                }
            )
            
            if response.status_code == 200:
                updated = True
    
    return updated


def upload_to_shopify(product_data, collection_id, tags):
    """ä¸Šå‚³å•†å“åˆ° Shopify"""
    
    original_title = product_data['title']
    description = product_data['description']
    manage_code = product_data['manage_code']
    cost = product_data['price']
    colors = product_data['colors']
    sizes = product_data['sizes']
    
    print(f"[ç¿»è­¯] æ­£åœ¨ç¿»è­¯: {original_title[:30]}...")
    translated = translate_with_chatgpt(original_title, description)
    
    selling_price = calculate_selling_price(cost, DEFAULT_WEIGHT)
    
    # å»ºç«‹ Options
    options = []
    if len(colors) > 1 or (len(colors) == 1 and colors[0] != 'æ¨™æº–'):
        options.append({'name': 'é¡è‰²', 'values': colors})
    if len(sizes) > 1 or (len(sizes) == 1 and sizes[0] != 'FREE'):
        options.append({'name': 'å°ºå¯¸', 'values': sizes})
    
    if not options:
        options = [{'name': 'Title', 'values': ['Default Title']}]
    
    # å»ºç«‹ Variantsï¼ˆé¡è‰² Ã— å°ºå¯¸ï¼‰
    variants = []
    if len(options) == 1:
        if options[0]['name'] == 'é¡è‰²':
            for color in colors:
                variants.append({
                    'option1': color,
                    'price': f"{selling_price:.2f}",
                    'sku': f"{manage_code}-{color}",
                    'weight': DEFAULT_WEIGHT,
                    'weight_unit': 'kg',
                    'inventory_management': None,
                    'inventory_policy': 'continue',
                    'requires_shipping': True,
                })
        elif options[0]['name'] == 'å°ºå¯¸':
            for size in sizes:
                variants.append({
                    'option1': size,
                    'price': f"{selling_price:.2f}",
                    'sku': f"{manage_code}-{size}",
                    'weight': DEFAULT_WEIGHT,
                    'weight_unit': 'kg',
                    'inventory_management': None,
                    'inventory_policy': 'continue',
                    'requires_shipping': True,
                })
        else:
            variants.append({
                'option1': 'Default Title',
                'price': f"{selling_price:.2f}",
                'sku': manage_code,
                'weight': DEFAULT_WEIGHT,
                'weight_unit': 'kg',
                'inventory_management': None,
                'inventory_policy': 'continue',
                'requires_shipping': True,
            })
    elif len(options) == 2:
        for color in colors:
            for size in sizes:
                variants.append({
                    'option1': color,
                    'option2': size,
                    'price': f"{selling_price:.2f}",
                    'sku': f"{manage_code}-{color}-{size}",
                    'weight': DEFAULT_WEIGHT,
                    'weight_unit': 'kg',
                    'inventory_management': None,
                    'inventory_policy': 'continue',
                    'requires_shipping': True,
                })
    else:
        variants.append({
            'option1': 'Default Title',
            'price': f"{selling_price:.2f}",
            'sku': manage_code,
            'weight': DEFAULT_WEIGHT,
            'weight_unit': 'kg',
            'inventory_management': None,
            'inventory_policy': 'continue',
            'requires_shipping': True,
        })
    
    # è™•ç†åœ–ç‰‡
    images_base64 = []
    color_images = product_data.get('color_images', {})  # {é¡è‰²ç´¢å¼•: URL}
    image_url_to_position = {}  # {URL: position}
    
    print(f"[åœ–ç‰‡] é–‹å§‹ä¸‹è¼‰ {len(product_data['images'])} å¼µåœ–ç‰‡...")
    
    for idx, img_url in enumerate(product_data['images'][:15]):  # æœ€å¤š 15 å¼µ
        print(f"[åœ–ç‰‡] ä¸‹è¼‰ä¸­ ({idx+1}/{min(len(product_data['images']), 15)}): {img_url[-30:]}")
        result = download_image_to_base64(img_url)
        
        if result['success']:
            position = idx + 1
            images_base64.append({
                'attachment': result['base64'],
                'position': position,
                'filename': f"workman_{manage_code}_{idx+1}.jpg"
            })
            image_url_to_position[img_url] = position
            print(f"[åœ–ç‰‡] âœ“ ä¸‹è¼‰æˆåŠŸ")
        else:
            print(f"[åœ–ç‰‡] âœ— ä¸‹è¼‰å¤±æ•—")
        
        time.sleep(0.3)
    
    print(f"[åœ–ç‰‡] æˆåŠŸä¸‹è¼‰ {len(images_base64)} å¼µåœ–ç‰‡")
    
    shopify_product = {
        'product': {
            'title': translated['title'],
            'body_html': translated['description'],
            'vendor': 'WORKMAN',
            'product_type': '',
            'status': 'active',
            'published': True,
            'handle': f"workman-{manage_code}",
            'options': options,
            'variants': variants,
            'images': images_base64,
            'tags': tags,
            'metafields_global_title_tag': translated['page_title'],
            'metafields_global_description_tag': translated['meta_description'],
            'metafields': [
                {
                    'namespace': 'custom',
                    'key': 'link',
                    'value': product_data['url'],
                    'type': 'url'
                }
            ]
        }
    }
    
    response = requests.post(
        shopify_api_url('products.json'),
        headers=get_shopify_headers(),
        json=shopify_product
    )
    
    if response.status_code == 201:
        created_product = response.json()['product']
        product_id = created_product['id']
        created_variants = created_product.get('variants', [])
        created_images = created_product.get('images', [])
        
        # æ›´æ–°æ¯å€‹ variant çš„ cost
        for cv in created_variants:
            requests.put(
                shopify_api_url(f"variants/{cv['id']}.json"),
                headers=get_shopify_headers(),
                json={'variant': {'id': cv['id'], 'cost': f"{cost:.2f}"}}
            )
        
        # åœ–ç‰‡èˆ‡ Variant å°æ‡‰
        # å»ºç«‹é¡è‰²åˆ° variant IDs çš„å°æ‡‰
        color_to_variant_ids = {}
        for cv in created_variants:
            color = cv.get('option1', '')
            if color:
                if color not in color_to_variant_ids:
                    color_to_variant_ids[color] = []
                color_to_variant_ids[color].append(cv['id'])
        
        # æŠŠé¡è‰²åœ–å’Œå°æ‡‰çš„ variants é—œè¯
        for color_idx, color_img_url in color_images.items():
            if color_idx < len(colors):
                color_name = colors[color_idx]
                variant_ids = color_to_variant_ids.get(color_name, [])
                
                if variant_ids and color_img_url in image_url_to_position:
                    position = image_url_to_position[color_img_url]
                    # æ‰¾åˆ°å°æ‡‰çš„ Shopify åœ–ç‰‡
                    for created_img in created_images:
                        if created_img.get('position') == position:
                            # æ›´æ–°åœ–ç‰‡çš„ variant_ids
                            requests.put(
                                shopify_api_url(f"products/{product_id}/images/{created_img['id']}.json"),
                                headers=get_shopify_headers(),
                                json={'image': {'id': created_img['id'], 'variant_ids': variant_ids}}
                            )
                            print(f"[åœ–ç‰‡å°æ‡‰] é¡è‰² {color_name} åœ–ç‰‡å·²é—œè¯ {len(variant_ids)} å€‹ variants")
                            break
        
        if collection_id:
            add_product_to_collection(product_id, collection_id)
        
        publish_to_all_channels(product_id)
        
        return {
            'success': True,
            'product': created_product,
            'translated': translated,
            'variants_count': len(created_variants)
        }
    else:
        print(f"[ERROR] Shopify éŒ¯èª¤: {response.text}")
        return {'success': False, 'error': response.text}


# ========== Flask è·¯ç”± ==========

@app.route('/')
def index():
    token_loaded = load_shopify_token()
    token_status = '<span style="color: green;">âœ“ å·²è¼‰å…¥</span>' if token_loaded else '<span style="color: red;">âœ— æœªè¨­å®š</span>'
    
    return f'''<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WORKMAN çˆ¬èŸ²å·¥å…·</title>
    <style>
        * {{ box-sizing: border-box; }}
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5; }}
        h1 {{ color: #333; border-bottom: 2px solid #FF6600; padding-bottom: 10px; }}
        .card {{ background: white; border-radius: 8px; padding: 20px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .btn {{ background: #FF6600; color: white; border: none; padding: 12px 24px; border-radius: 5px; cursor: pointer; font-size: 16px; margin-right: 10px; margin-bottom: 10px; }}
        .btn:hover {{ background: #E55A00; }}
        .btn:disabled {{ background: #ccc; cursor: not-allowed; }}
        .btn-secondary {{ background: #3498db; }}
        .btn-work {{ background: #795548; }}
        .btn-mens {{ background: #2980b9; }}
        .btn-womens {{ background: #e91e63; }}
        .btn-kids {{ background: #4caf50; }}
        .progress-bar {{ width: 100%; height: 20px; background: #eee; border-radius: 10px; overflow: hidden; margin: 10px 0; }}
        .progress-fill {{ height: 100%; background: linear-gradient(90deg, #FF6600, #FFA500); transition: width 0.3s; }}
        .status {{ padding: 10px; background: #f8f9fa; border-radius: 5px; margin-top: 10px; }}
        .log {{ max-height: 300px; overflow-y: auto; font-family: monospace; font-size: 13px; background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 5px; }}
        .stats {{ display: flex; gap: 15px; margin-top: 15px; flex-wrap: wrap; }}
        .stat {{ flex: 1; min-width: 80px; text-align: center; padding: 15px; background: #f8f9fa; border-radius: 5px; }}
        .stat-number {{ font-size: 24px; font-weight: bold; color: #FF6600; }}
        .stat-label {{ font-size: 11px; color: #666; margin-top: 5px; }}
    </style>
</head>
<body>
    <h1>ğŸ”§ WORKMAN çˆ¬èŸ²å·¥å…·</h1>
    
    <div class="card">
        <h3>Shopify é€£ç·šç‹€æ…‹</h3>
        <p>Token: {token_status}</p>
        <button class="btn btn-secondary" onclick="testShopify()">æ¸¬è©¦é€£ç·š</button>
    </div>
    
    <div class="card">
        <h3>é–‹å§‹çˆ¬å–</h3>
        <p>çˆ¬å– workman.jp æ‰€æœ‰å•†å“ä¸¦ä¸Šæ¶åˆ° Shopify</p>
        <p style="color: #666; font-size: 14px;">â€» å·²å­˜åœ¨å•†å“æœƒè‡ªå‹•åŒæ­¥åƒ¹æ ¼</p>
        <button class="btn btn-work" id="startWorkBtn" onclick="startScrape('work')">ğŸ”§ çˆ¬å–ä½œæ¥­æœ</button>
        <button class="btn btn-mens" id="startMensBtn" onclick="startScrape('mens')">ğŸ‘” çˆ¬å–ç”·è£</button>
        <button class="btn btn-womens" id="startWomensBtn" onclick="startScrape('womens')">ğŸ‘— çˆ¬å–å¥³è£</button>
        <button class="btn btn-kids" id="startKidsBtn" onclick="startScrape('kids')">ğŸ‘¶ çˆ¬å–å…’ç«¥æœ</button>
        <button class="btn" id="startAllBtn" onclick="startScrape('all')">ğŸš€ å…¨éƒ¨çˆ¬å–</button>
        
        <div id="progressSection" style="display: none;">
            <div class="progress-bar">
                <div class="progress-fill" id="progressFill" style="width: 0%"></div>
            </div>
            <div class="status" id="statusText">æº–å‚™ä¸­...</div>
            
            <div class="stats">
                <div class="stat">
                    <div class="stat-number" id="uploadedCount">0</div>
                    <div class="stat-label">å·²ä¸Šæ¶</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="priceUpdatedCount" style="color: #3498db;">0</div>
                    <div class="stat-label">åƒ¹æ ¼æ›´æ–°</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="skippedCount">0</div>
                    <div class="stat-label">å·²è·³é</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="draftCount" style="color: #e67e22;">0</div>
                    <div class="stat-label">è¨­ç‚ºè‰ç¨¿</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="errorCount">0</div>
                    <div class="stat-label">éŒ¯èª¤</div>
                </div>
            </div>
        </div>
    </div>
    
    <div class="card">
        <h3>åŸ·è¡Œæ—¥èªŒ</h3>
        <div class="log" id="logArea">ç­‰å¾…é–‹å§‹...</div>
    </div>

    <script>
        let pollInterval = null;
        function log(msg, type = '') {{
            const logArea = document.getElementById('logArea');
            const time = new Date().toLocaleTimeString();
            const color = type === 'success' ? '#4ec9b0' : type === 'error' ? '#f14c4c' : '#d4d4d4';
            logArea.innerHTML += '<div style="color:' + color + '">[' + time + '] ' + msg + '</div>';
            logArea.scrollTop = logArea.scrollHeight;
        }}
        function clearLog() {{ document.getElementById('logArea').innerHTML = ''; }}
        function disableButtons(disabled) {{
            document.getElementById('startWorkBtn').disabled = disabled;
            document.getElementById('startMensBtn').disabled = disabled;
            document.getElementById('startWomensBtn').disabled = disabled;
            document.getElementById('startKidsBtn').disabled = disabled;
            document.getElementById('startAllBtn').disabled = disabled;
        }}
        async function testShopify() {{
            log('æ¸¬è©¦ Shopify é€£ç·š...');
            try {{
                const res = await fetch('/api/test-shopify');
                const data = await res.json();
                if (data.success) log('âœ“ é€£ç·šæˆåŠŸï¼', 'success');
                else log('âœ— é€£ç·šå¤±æ•—: ' + data.error, 'error');
            }} catch (e) {{ log('âœ— è«‹æ±‚å¤±æ•—: ' + e.message, 'error'); }}
        }}
        async function startScrape(category) {{
            clearLog(); log('é–‹å§‹çˆ¬å–æµç¨‹ (' + category + ')...');
            disableButtons(true);
            document.getElementById('progressSection').style.display = 'block';
            try {{
                const res = await fetch('/api/start?category=' + category, {{ method: 'POST' }});
                const data = await res.json();
                if (!data.success) {{ log('âœ— ' + data.error, 'error'); disableButtons(false); return; }}
                log('âœ“ çˆ¬å–ä»»å‹™å·²å•Ÿå‹•', 'success');
                pollInterval = setInterval(pollStatus, 1000);
            }} catch (e) {{ log('âœ— ' + e.message, 'error'); disableButtons(false); }}
        }}
        async function pollStatus() {{
            try {{
                const res = await fetch('/api/status');
                const data = await res.json();
                const percent = data.total > 0 ? (data.progress / data.total * 100) : 0;
                document.getElementById('progressFill').style.width = percent + '%';
                document.getElementById('statusText').textContent = data.current_product + ' (' + data.progress + '/' + data.total + ')';
                document.getElementById('uploadedCount').textContent = data.uploaded;
                document.getElementById('priceUpdatedCount').textContent = data.price_updated || 0;
                document.getElementById('skippedCount').textContent = data.skipped;
                document.getElementById('draftCount').textContent = data.set_to_draft || 0;
                document.getElementById('errorCount').textContent = data.errors.length;
                if (!data.running && data.progress > 0) {{
                    clearInterval(pollInterval);
                    disableButtons(false);
                    log('========== çˆ¬å–å®Œæˆ ==========', 'success');
                }}
            }} catch (e) {{ console.error(e); }}
        }}
    </script>
</body>
</html>'''


@app.route('/api/status')
def get_status():
    return jsonify(scrape_status)


@app.route('/api/start', methods=['GET', 'POST'])
def api_start():
    global scrape_status
    
    if scrape_status['running']:
        return jsonify({'success': False, 'error': 'çˆ¬å–æ­£åœ¨é€²è¡Œä¸­'})
    
    if not load_shopify_token():
        return jsonify({'success': False, 'error': 'ç’°å¢ƒè®Šæ•¸æœªè¨­å®š'})
    
    category = request.args.get('category', 'all')
    
    thread = threading.Thread(target=run_scrape, args=(category,))
    thread.start()
    
    return jsonify({'success': True, 'message': f'WORKMAN çˆ¬èŸ²å·²å•Ÿå‹• ({category})'})


from flask import request


def run_scrape(category='all'):
    global scrape_status
    
    try:
        scrape_status = {
            "running": True,
            "progress": 0,
            "total": 0,
            "current_product": "",
            "products": [],
            "errors": [],
            "uploaded": 0,
            "skipped": 0,
            "skipped_exists": 0,
            "out_of_stock": 0,
            "set_to_draft": 0,
            "price_updated": 0
        }
        
        categories_to_scrape = []
        if category == 'all':
            categories_to_scrape = ['work', 'mens', 'womens', 'kids']
        elif category in CATEGORIES:
            categories_to_scrape = [category]
        else:
            scrape_status['errors'].append({'error': f'æœªçŸ¥åˆ†é¡: {category}'})
            scrape_status['running'] = False
            return
        
        for cat_key in categories_to_scrape:
            cat_info = CATEGORIES[cat_key]
            collection_name = cat_info['collection']
            tags = cat_info['tags']
            
            scrape_status['current_product'] = f"æ­£åœ¨è¨­å®š Collection: {collection_name}..."
            collection_id = get_or_create_collection(collection_name)
            print(f"[INFO] Collection ID: {collection_id}")
            
            scrape_status['current_product'] = f"æ­£åœ¨å–å¾— {collection_name} å•†å“åˆ—è¡¨..."
            collection_products_map = get_collection_products_with_details(collection_id)
            existing_handles = set(collection_products_map.keys())
            
            scrape_status['current_product'] = f"æ­£åœ¨å¾ workman.jp å–å¾— {collection_name} å•†å“é€£çµ..."
            product_links = fetch_all_product_links(cat_key)
            scrape_status['total'] += len(product_links)
            
            # è¨˜éŒ„å®˜ç¶²æœ‰çš„å•†å“ handle
            website_handles = set()
            
            for idx, link in enumerate(product_links):
                scrape_status['progress'] += 1
                scrape_status['current_product'] = f"è™•ç†ä¸­: {link[-20:]}"
                
                product_data = parse_product_page(link)
                
                if not product_data:
                    scrape_status['errors'].append({'url': link, 'error': 'è§£æå¤±æ•—'})
                    continue
                
                my_handle = f"workman-{product_data['manage_code']}"
                website_handles.add(my_handle)
                
                # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if my_handle in existing_handles:
                    existing_info = collection_products_map[my_handle]
                    
                    scrape_status['current_product'] = f"æª¢æŸ¥åƒ¹æ ¼: {product_data['title'][:20]}"
                    if update_product_prices(product_data, existing_info):
                        print(f"[åƒ¹æ ¼åŒæ­¥] {product_data['title']}")
                        scrape_status['price_updated'] += 1
                    else:
                        print(f"[è·³é] å·²å­˜åœ¨ï¼Œåƒ¹æ ¼ç„¡è®Šå‹•: {my_handle}")
                    
                    scrape_status['skipped_exists'] += 1
                    scrape_status['skipped'] += 1
                    continue
                
                result = upload_to_shopify(product_data, collection_id, tags)
                
                if result['success']:
                    translated_title = result.get('translated', {}).get('title', product_data['title'])
                    variants_count = result.get('variants_count', 0)
                    print(f"[æˆåŠŸ] {translated_title} ({variants_count} variants)")
                    scrape_status['uploaded'] += 1
                    scrape_status['products'].append({
                        'handle': my_handle,
                        'title': translated_title,
                        'status': 'success'
                    })
                else:
                    print(f"[å¤±æ•—] {product_data['title']}: {result['error']}")
                    scrape_status['errors'].append({
                        'handle': my_handle,
                        'title': product_data['title'],
                        'error': result['error']
                    })
                
                time.sleep(1)
            
            # è¨­ç‚ºè‰ç¨¿ï¼šå·²ä¸Šæ¶ä½†å®˜ç¶²å·²ä¸‹æ¶çš„å•†å“
            scrape_status['current_product'] = f"æ­£åœ¨æª¢æŸ¥ {collection_name} éœ€è¦è¨­ç‚ºè‰ç¨¿çš„å•†å“..."
            
            for my_handle, product_info in collection_products_map.items():
                if my_handle not in website_handles:
                    scrape_status['current_product'] = f"è¨­ç‚ºè‰ç¨¿: {my_handle}"
                    print(f"[è¨­ç‚ºè‰ç¨¿] {my_handle} - å®˜ç¶²å·²ä¸‹æ¶")
                    if set_product_to_draft(product_info['product_id']):
                        scrape_status['set_to_draft'] += 1
                    time.sleep(0.5)
        
        scrape_status['current_product'] = "å®Œæˆï¼"
        
    except Exception as e:
        print(f"[ERROR] çˆ¬å–éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        scrape_status['errors'].append({'error': str(e)})
    finally:
        scrape_status['running'] = False


@app.route('/api/test-shopify')
def test_shopify():
    if not load_shopify_token():
        return jsonify({'success': False, 'error': 'ç’°å¢ƒè®Šæ•¸æœªè¨­å®š'})
    
    response = requests.get(
        shopify_api_url('shop.json'),
        headers=get_shopify_headers()
    )
    
    if response.status_code == 200:
        return jsonify({'success': True, 'shop': response.json()['shop']})
    else:
        return jsonify({'success': False, 'error': response.text}), 400


@app.route('/api/test-scrape')
def test_scrape():
    """æ¸¬è©¦çˆ¬å–"""
    # æ¸¬è©¦å–å¾—ä¸€å€‹å•†å“
    test_url = "https://workman.jp/shop/g/g2300044989124/"
    product = parse_product_page(test_url)
    
    if product:
        return jsonify({
            'success': True,
            'product': {
                'title': product['title'],
                'price': product['price'],
                'product_code': product['product_code'],
                'manage_code': product['manage_code'],
                'colors': product['colors'],
                'sizes': product['sizes'],
                'images_count': len(product['images'])
            }
        })
    else:
        return jsonify({'success': False, 'error': 'è§£æå¤±æ•—'})


if __name__ == '__main__':
    print("=" * 50)
    print("WORKMAN çˆ¬èŸ²å·¥å…·")
    print("=" * 50)
    
    port = int(os.environ.get('PORT', 8080))
    print(f"é–‹å•Ÿç€è¦½å™¨è¨ªå•: http://localhost:{port}")
    print("=" * 50)
    
    app.run(host='0.0.0.0', port=port, debug=False)
